{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f96611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "# wv = KeyedVectors.load_word2vec_format(\"ko.vec\", binary=False)\n",
    "# print(wv.most_similar(\"ì‚¬ë‘\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151caaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.3 in /opt/conda/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e47cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.9/site-packages (0.9.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from fasttext) (59.4.0)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.9/site-packages (from fasttext) (2.13.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from fasttext) (1.21.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841f2d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.4\n",
      "1.3.3\n",
      "2.6.0\n",
      "3.6.5\n",
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(nltk.__version__)\n",
    "print(gensim.__version__)\n",
    "\n",
    "import re\n",
    "from konlpy.tag import Mecab\n",
    "import fasttext\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5c66a",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7733466e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ê³µë¶€ ì‹œì‘í•´ë„ ë ê¹Œ</td>\n",
       "      <td>ê³µë¶€ëŠ” ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>ë°”ë‹¤ ë³´ëŸ¬ ê°€ìê³  í•´ë³¼ê¹Œ</td>\n",
       "      <td>ë°”ë‹¤ëŠ” ì‚¬ê³„ì ˆ ë‚´ë‚´ ì¢‹ì•„ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>í˜¼ì ìˆìœ¼ë‹ˆ í˜ì´ë“œë„¤</td>\n",
       "      <td>í•œë™ì•ˆì€ í˜ë“¤ì§€ë„ ëª°ë¼ìš”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>ê°ì •ì‹¸ì›€ ê·¸ë§Œí•˜ê³  ì‹¶ì–´</td>\n",
       "      <td>ìì¡´ì‹¬ì„ ì„¸ìš°ì§€ ë§ˆì„¸ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>ë’¤ì— ëˆ„ê°€ ë”°ë¼ ì˜¤ëŠ” ê²ƒ ê°™ì•„ ë¬´ì„œì›Œ</td>\n",
       "      <td>í•­ìƒ ì¡°ì‹¬í•˜ì„¸ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                A  label\n",
       "220             ê³µë¶€ ì‹œì‘í•´ë„ ë ê¹Œ      ê³µë¶€ëŠ” ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "1895         ë°”ë‹¤ ë³´ëŸ¬ ê°€ìê³  í•´ë³¼ê¹Œ  ë°”ë‹¤ëŠ” ì‚¬ê³„ì ˆ ë‚´ë‚´ ì¢‹ì•„ìš”.      0\n",
       "8747           í˜¼ì ìˆìœ¼ë‹ˆ í˜ì´ë“œë„¤   í•œë™ì•ˆì€ í˜ë“¤ì§€ë„ ëª°ë¼ìš”.      1\n",
       "8909          ê°ì •ì‹¸ì›€ ê·¸ë§Œí•˜ê³  ì‹¶ì–´    ìì¡´ì‹¬ì„ ì„¸ìš°ì§€ ë§ˆì„¸ìš”.      2\n",
       "1352  ë’¤ì— ëˆ„ê°€ ë”°ë¼ ì˜¤ëŠ” ê²ƒ ê°™ì•„ ë¬´ì„œì›Œ        í•­ìƒ ì¡°ì‹¬í•˜ì„¸ìš”.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"./ChatbotData.csv\"\n",
    "\n",
    "chatbot_df = pd.read_csv(file_path)\n",
    "\n",
    "chatbot_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631ef34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = chatbot_df['Q'], chatbot_df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "960c82bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë“±ì¥í•œ íŠ¹ìˆ˜ë¬¸ìì™€ ë¹ˆë„ìˆ˜:\n",
      "'.': 13942íšŒ\n",
      "'?': 1845íšŒ\n",
      "'!': 351íšŒ\n",
      "',': 92íšŒ\n",
      "'~': 55íšŒ\n",
      "''': 9íšŒ\n",
      "';': 6íšŒ\n",
      "'â€¦': 5íšŒ\n",
      "'-': 3íšŒ\n",
      "'%': 2íšŒ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# íŠ¹ìˆ˜ë¬¸ìë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\n",
    "def extract_special_chars(text):\n",
    "    return re.findall(r\"[^\\w\\sê°€-í£]\", text)  # ì˜ë¬¸ì, ìˆ«ì, í•œê¸€, ê³µë°±ì„ ì œì™¸í•œ íŠ¹ìˆ˜ë¬¸ì ì¶”ì¶œ\n",
    "\n",
    "# Qì™€ A ì»¬ëŸ¼ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ìˆ˜ì§‘\n",
    "q_specials = chatbot_df['Q'].dropna().apply(extract_special_chars).sum()\n",
    "a_specials = chatbot_df['A'].dropna().apply(extract_special_chars).sum()\n",
    "\n",
    "# ì „ì²´ íŠ¹ìˆ˜ë¬¸ì ì¹´ìš´íŠ¸\n",
    "total_specials = Counter(q_specials + a_specials)\n",
    "\n",
    "# ê²°ê³¼ ë³´ê¸°\n",
    "print(\"ë“±ì¥í•œ íŠ¹ìˆ˜ë¬¸ìì™€ ë¹ˆë„ìˆ˜:\")\n",
    "for char, count in total_specials.most_common():\n",
    "    print(f\"'{char}': {count}íšŒ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95927780",
   "metadata": {},
   "source": [
    "íŠ¹ìˆ˜ë¬¸ì ë³´ì¡´ ëŒ€ìƒ : . (ë§ˆì¹¨í‘œ) ? (ë¬¼ìŒí‘œ) ! (ëŠë‚Œí‘œ) , (ì‰¼í‘œ) ~ (ë§íˆ¬, ê°ì • í‘œí˜„) ' (ì‘ì€ë”°ì˜´í‘œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9348d6a",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ì •ì œ, ë°ì´í„° í† í°í™”\n",
    "ë°ì´í„° ì •ì œ\n",
    "- ì˜ë¬¸ìì˜ ê²½ìš°, ëª¨ë‘ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
    "- ì˜ë¬¸ìì™€ í•œê¸€, ìˆ«ì, ì£¼ìš” íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œì™¸í•˜ê³  ì •ê·œì‹ì„ í™œìš©í•˜ì—¬ ëª¨ë‘ ì œê±°  \n",
    "- ì£¼ìš” íŠ¹ìˆ˜ë¬¸ì :  . (ë§ˆì¹¨í‘œ) ? (ë¬¼ìŒí‘œ) ! (ëŠë‚Œí‘œ) , (ì‰¼í‘œ) ~ (ë§íˆ¬, ê°ì • í‘œí˜„) ' (ì‘ì€ë”°ì˜´í‘œ)\n",
    "\n",
    "ë°ì´í„° í† í°í™”\n",
    "- mecab ì‚¬ìš©\n",
    "- src, tgt ì…ë ¥ìœ¼ë¡œ ë°›ìŒ\n",
    "- preprocess_sentence()ë¡œ ì •ì œ, í† í°í™”\n",
    "- í† í¬ë‚˜ì´ì¦ˆí•¨ìˆ˜ ì‚¬ìš© mecab.morphs ì „ë‹¬\n",
    "- í† í° ê°œìˆ˜ê°€ ì¼ì • ê¸¸ì´ ì´ìƒì¸ ë¬¸ì¥ì€ ë°ì´í„°ì—ì„œ ì œì™¸ : max len= 15\n",
    "- ì¤‘ë³µë˜ëŠ” ë¬¸ì¥ ì œì™¸ : (src, tgt) ìŒ ë¹„êµ X, src, tgt ê°ê° ê²€ì‚¬ ì¤‘ë³µìŒì´ ííŠ¸ëŸ¬ì§€ì§€ ì•Šë„ë¡ ìœ ì˜\n",
    "- questionsì™€ answersë¥¼ ê°ê° que_corpus, ans_corpusì— í† í°í™” í•˜ì—¬ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883f260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # ëª¨ë“  ì˜ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # ì˜ë¬¸ì, ìˆ«ì, í•œê¸€, ê³µë°±, ê·¸ë¦¬ê³  ì£¼ìš” íŠ¹ìˆ˜ë¬¸ì(.,!?~')ë¥¼ ì œì™¸í•œ ëª¨ë“  ë¬¸ì ì œê±°\n",
    "    pattern = r\"[^a-z0-9ê°€-í£\\s.,!?~']\"\n",
    "    sentence = re.sub(pattern, \"\", sentence)\n",
    "    \n",
    "    # ì¤‘ë³µëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì…ë‹ˆë‹¤.\n",
    "    return ' '.join(sentence.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a100c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²´ ë¬¸ì¥ì˜ 95%ëŠ” ê¸¸ì´ 14 ì´í•˜ì…ë‹ˆë‹¤. â†’ ì¶”ì²œ max_len = 14\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def suggest_max_len(Q, A, tokenizer):\n",
    "    # 1. ì „ì²˜ë¦¬ ë° í† í°í™”\n",
    "    Q_tokens = Q.apply(lambda x: tokenizer(preprocess_sentence(x)))\n",
    "    A_tokens = A.apply(lambda x: tokenizer(preprocess_sentence(x)))\n",
    "\n",
    "    # 2. ê¸¸ì´ ì¶”ì¶œ\n",
    "    q_lens = Q_tokens.apply(len)\n",
    "    a_lens = A_tokens.apply(len)\n",
    "\n",
    "    # 3. í†µí•©í•˜ì—¬ ê¸¸ì´ ë¶„í¬ í™•ì¸\n",
    "    all_lens = pd.concat([q_lens, a_lens])\n",
    "    \n",
    "    # 4. ì‹œê°í™”\n",
    "    plt.hist(all_lens, bins=30, color='skyblue')\n",
    "    plt.title(\"Token Length Distribution (Q + A)\")\n",
    "    plt.xlabel(\"Token Length\")\n",
    "    plt.ylabel(\"Number of Sentences\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # 5. ìµœëŒ€ ê¸¸ì´ ì¶”ì²œ (ì˜ˆ: ìƒìœ„ 95% ê¸°ì¤€)\n",
    "    max_len_95 = int(np.percentile(all_lens, 95))\n",
    "    print(f\"âœ… ì „ì²´ ë¬¸ì¥ì˜ 95%ëŠ” ê¸¸ì´ {max_len_95} ì´í•˜ì…ë‹ˆë‹¤. â†’ ì¶”ì²œ max_len = {max_len_95}\")\n",
    "    \n",
    "    return max_len_95\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "tokenizer = mecab.morphs\n",
    "\n",
    "recommended_max_len = suggest_max_len(chatbot_df['Q'], chatbot_df['A'], tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9409b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()\n",
    "#max_len = 15ë¡œ ì„¤ì •\n",
    "def build_corpus(Q, A, token_len=15):\n",
    "    temp = pd.concat([Q, A], axis=1)\n",
    "    temp.columns = ['Q', 'A']  # ì—´ ì´ë¦„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •\n",
    "\n",
    "    # 1. ì¤‘ë³µ ì œê±° (src, tgt ëŒ€ì‘ ìœ ì§€)\n",
    "    dup_q_idx = temp[temp.duplicated('Q')].index\n",
    "    dup_a_idx = temp[temp.duplicated('A')].index\n",
    "    dup_idx = dup_q_idx.union(dup_a_idx)\n",
    "    temp = temp.drop(index=dup_idx).reset_index(drop=True)\n",
    "\n",
    "    # 2. ì „ì²˜ë¦¬\n",
    "    temp['Q'] = temp['Q'].apply(preprocess_sentence)\n",
    "    temp['A'] = temp['A'].apply(preprocess_sentence)\n",
    "\n",
    "    # 3. í˜•íƒœì†Œ ë¶„ì„ (mecab.morphs ì‚¬ìš©)\n",
    "    temp['Q'] = temp['Q'].apply(mecab.morphs)\n",
    "    temp['A'] = temp['A'].apply(mecab.morphs)\n",
    "\n",
    "    # 4. ê¸¸ì´ í•„í„°ë§\n",
    "    temp = temp[(temp['Q'].apply(len) <= token_len) & (temp['A'].apply(len) <= token_len)].reset_index(drop=True)\n",
    "\n",
    "    # 5. ê²°ê³¼ ë°˜í™˜\n",
    "    que_corpus = temp['Q'].tolist()\n",
    "    ans_corpus = temp['A'].tolist()\n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4718f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = build_corpus(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb93bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(que_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e684388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7102"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18f2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ìŠ¬í””', 0.7216662764549255), ('í–‰ë³µ', 0.6759077310562134), ('ì ˆë§', 0.6468985080718994), ('ê¸°ì¨', 0.6458414196968079), ('ì´ë³„', 0.6334798336029053), ('ì¶”ì–µ', 0.6320937275886536), ('ì¸ìƒ', 0.6216273307800293), ('ì• ì •', 0.6206069588661194), ('ì—°ì¸', 0.6186063289642334), ('ìœ í˜¹', 0.5965287685394287)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load_word2vec_format(\"ko.vec\", binary=False)\n",
    "print(wv.most_similar(\"ì‚¬ë‘\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7dba2",
   "metadata": {},
   "source": [
    "# data augmentation\n",
    "- lexical substitutionì„ ì ìš©\n",
    "- augmentationëœ que_corpusì™€ ì›ë³¸ ans_corpus\n",
    "- augmentationëœ ans_corpusì™€ ì›ë³¸ que_corpusê°€ ë³‘ë ¬ì„ ì´ë£¨ë„ë¡\n",
    "\n",
    "-> ì „ì²´ ë°ì´í„°ê°€ ì›ë˜ì˜ 3ë°° ê°€ëŸ‰ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ë„ë¡ í•œë‹¤. \n",
    "\n",
    "- ì•½ 3ë§Œê°œ ì •ë„ì˜ ë°ì´í„°ë¡œ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bea8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "def lexical_sub(old_src, wv):\n",
    "    topn=3\n",
    "    similarity_threshold=0.5\n",
    "    pos_tags=['NNP', 'VV', 'VA', 'NP', 'NNG']\n",
    "    max_versions = 3\n",
    "    original = [tok for tok, _ in old_src]\n",
    "    candidate_subs = []\n",
    "\n",
    "    for i, (tok, pos) in enumerate(old_src):\n",
    "        if pos in pos_tags and tok in wv:\n",
    "            try:\n",
    "                similar_list = wv.most_similar(tok, topn=topn)\n",
    "                filtered = [w for w, sim in similar_list if sim >= similarity_threshold]\n",
    "                if filtered:\n",
    "                    candidate_subs.append((i, filtered))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    if not candidate_subs:\n",
    "        return [original]\n",
    "\n",
    "    all_versions = []\n",
    "    positions, replacements = zip(*candidate_subs)\n",
    "\n",
    "    # ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "    all_combos = list(itertools.product(*replacements))\n",
    "\n",
    "    # ìµœëŒ€ max_versions-1ê°œë§Œ ìƒ˜í”Œë§ (ì›ë³¸ í¬í•¨í•˜ë¯€ë¡œ -1)\n",
    "    sampled_combos = random.sample(all_combos, min(max_versions - 1, len(all_combos)))\n",
    "    for combo in sampled_combos:\n",
    "        new_sent = original.copy()\n",
    "        for idx, rep in zip(positions, combo):\n",
    "            new_sent[idx] = rep\n",
    "        all_versions.append(new_sent)\n",
    "\n",
    "    all_versions.insert(0, original)\n",
    "    return all_versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f50c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_partial_pairs_df(enc_src, dec_tgt, wv):\n",
    "    \"\"\"\n",
    "    enc_src, dec_tgt: mecab.pos()ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "    ë°˜í™˜: ì›ë³¸/ë¶€ë¶„ ì¦ê°•ëœ ë³‘ë ¬ìŒë§Œ í¬í•¨ëœ DataFrame\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for enc_tokens, dec_tokens in zip(enc_src, dec_tgt):\n",
    "        # 1. ì›ë¬¸ ì¶”ê°€\n",
    "        original_enc = [tok for tok, _ in enc_tokens]\n",
    "        original_dec = [tok for tok, _ in dec_tokens]\n",
    "        rows.append({'encoder': ' '.join(original_enc), 'decoder': ' '.join(original_dec)})\n",
    "\n",
    "        # 2. Që§Œ ì¦ê°•\n",
    "        enc_augments = lexical_sub(enc_tokens, wv)\n",
    "        for aug in enc_augments[1:]:  # ì›ë³¸ ì œì™¸\n",
    "            rows.append({'encoder': ' '.join(aug), 'decoder': ' '.join(original_dec)})\n",
    "\n",
    "        # 3. Aë§Œ ì¦ê°•\n",
    "        dec_augments = lexical_sub(dec_tokens, wv)\n",
    "        for aug in dec_augments[1:]:  # ì›ë³¸ ì œì™¸\n",
    "            rows.append({'encoder': ' '.join(original_enc), 'decoder': ' '.join(aug)})\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a3421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          encoder         decoder\n",
      "0        12 ì‹œ ë•¡ !   í•˜ë£¨ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "1        12 ì‹œ ë•¡ !   ë³´ë¦„ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "2        12 ì‹œ ë•¡ !  ì¼ì£¼ì¼ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "3   1 ì§€ë§ í•™êµ ë–¨ì–´ì¡Œ ì–´     ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
      "4  1 ì¤‘í‡´ í•™êµì˜ ë–¨ì–´ì¡Œ ì–´     ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                encoder                         decoder\n",
       "0                             12 ì‹œ ë•¡ !                   í•˜ë£¨ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
       "1                             12 ì‹œ ë•¡ !                   ë³´ë¦„ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
       "2                             12 ì‹œ ë•¡ !                  ì¼ì£¼ì¼ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
       "3                        1 ì§€ë§ í•™êµ ë–¨ì–´ì¡Œ ì–´                     ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
       "4                       1 ì¤‘í‡´ í•™êµì˜ ë–¨ì–´ì¡Œ ì–´                     ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
       "...                                ...                             ...\n",
       "32636     í˜ë“  ì—°ì•  ì¢‹ ì€ ì—°ì•  ë¼ëŠ” ê²Œ ë¬´ìŠ¨ ì°¨ì´ ì¼ê¹Œ ?    ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆ ëŠ” ì‚¬ì´ ì—¬ë¶€ ì¸ ê±° ê°™ ì•„ìš” .\n",
       "32637  í˜ë“  ì„±í–‰ìœ„ ê´œì°® ì€ ì„±í–‰ìœ„ ë¼ëŠ” ê²Œ ë¬´ìŠ¨ ë³€í™” ì¼ê¹Œ ?    ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆ ëŠ” ì‚¬ì´ ì—¬ë¶€ ì¸ ê±° ê°™ ì•„ìš” .\n",
       "32638   í˜ë“  ì„±í–‰ìœ„ ë‚« ì€ ë™ì„±ì•  ë¼ëŠ” ê²Œ ë¬´ìŠ¨ ê²©ì°¨ ì¼ê¹Œ ?    ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆ ëŠ” ì‚¬ì´ ì—¬ë¶€ ì¸ ê±° ê°™ ì•„ìš” .\n",
       "32639     í˜ë“  ì—°ì•  ì¢‹ ì€ ì—°ì•  ë¼ëŠ” ê²Œ ë¬´ìŠ¨ ì°¨ì´ ì¼ê¹Œ ?  ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆì—ˆ ëŠ” ê°„ì˜ ìœ ë¬´ ì¸ ê±° ê°™ì´ ì•„ìš” .\n",
       "32640     í˜ë“  ì—°ì•  ì¢‹ ì€ ì—°ì•  ë¼ëŠ” ê²Œ ë¬´ìŠ¨ ì°¨ì´ ì¼ê¹Œ ?   ì˜ í—¤ì–´ì§ˆ ìˆ˜ ì—† ëŠ” ê°„ì˜ ìœ ë¬´ ì¸ ê±° ë˜‘ê°™ ì•„ìš” .\n",
       "\n",
       "[32641 rows x 2 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross_augmented = augment_pairwise_cross_product(que_corpus, ans_corpus, wv)\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()\n",
    "\n",
    "enc_src = [mecab.pos(' '.join(q)) for q in que_corpus]\n",
    "dec_tgt = [mecab.pos(' '.join(a)) for a in ans_corpus]\n",
    "\n",
    "aug_df = augment_partial_pairs_df(enc_src, dec_tgt, wv)\n",
    "print(aug_df.head())\n",
    "aug_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ebce836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œ ìˆ˜: 32641\n",
      "==================================================\n",
      "[1]\n",
      "Encoder: 12 ì‹œ ë•¡ !\n",
      "Decoder: í•˜ë£¨ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "--------------------------------------------------\n",
      "[2]\n",
      "Encoder: 12 ì‹œ ë•¡ !\n",
      "Decoder: ë³´ë¦„ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "--------------------------------------------------\n",
      "[3]\n",
      "Encoder: 12 ì‹œ ë•¡ !\n",
      "Decoder: ì¼ì£¼ì¼ ê°€ ë˜ ê°€ ë„¤ìš” .\n",
      "--------------------------------------------------\n",
      "[4]\n",
      "Encoder: 1 ì§€ë§ í•™êµ ë–¨ì–´ì¡Œ ì–´\n",
      "Decoder: ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
      "--------------------------------------------------\n",
      "[5]\n",
      "Encoder: 1 ì¤‘í‡´ í•™êµì˜ ë–¨ì–´ì¡Œ ì–´\n",
      "Decoder: ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
      "--------------------------------------------------\n",
      "[6]\n",
      "Encoder: 1 ì¤‘í‡´ ì¤‘ê³ ë“±í•™êµ ë–¨ì–´ì¡Œ ì–´\n",
      "Decoder: ìœ„ë¡œ í•´ ë“œë¦½ë‹ˆë‹¤ .\n",
      "--------------------------------------------------\n",
      "[7]\n",
      "Encoder: 3 ë°• 4 ì¼ ë†€ ëŸ¬ ê°€ ê³  ì‹¶ ë‹¤\n",
      "Decoder: ì—¬í–‰ ì€ ì–¸ì œë‚˜ ì¢‹ ì£  .\n",
      "--------------------------------------------------\n",
      "[8]\n",
      "Encoder: 3 ë°• 4 ì¼ ìš¸ ëŸ¬ ê°€ ê³  ì‹¶ ë‹¤\n",
      "Decoder: ì—¬í–‰ ì€ ì–¸ì œë‚˜ ì¢‹ ì£  .\n",
      "--------------------------------------------------\n",
      "[9]\n",
      "Encoder: 3 ë°• 4 ì¼ ì‚´ ëŸ¬ ê°€ ê³  ì‹¶ ë‹¤\n",
      "Decoder: ì—¬í–‰ ì€ ì–¸ì œë‚˜ ì¢‹ ì£  .\n",
      "--------------------------------------------------\n",
      "[10]\n",
      "Encoder: 3 ë°• 4 ì¼ ë†€ ëŸ¬ ê°€ ê³  ì‹¶ ë‹¤\n",
      "Decoder: í•­í•´ ì€ ì–¸ì œë‚˜ ë‚« ì£  .\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def inspect_augmented_samples(df, n=5):\n",
    "    print(f\"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(df)}\")\n",
    "    print(\"=\"*50)\n",
    "    for i in range(n):\n",
    "        print(f\"[{i+1}]\")\n",
    "        print(\"Encoder:\", df.iloc[i]['encoder'])\n",
    "        print(\"Decoder:\", df.iloc[i]['decoder'])\n",
    "        print(\"-\" * 50)\n",
    "inspect_augmented_samples(aug_df, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ac6b698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>decoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29463</th>\n",
       "      <td>ì˜¤ëŠ˜ ì„œì  ì—ì„œ ì´ìƒ í˜• ë´¤ ì–´</td>\n",
       "      <td>ì—´ì‡  ë‚´ ì„œ ë§ë¡œ ì„ ê±¸ ì–´ ë³´ ì„¸ìš” .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15081</th>\n",
       "      <td>ì›ë§ ê°</td>\n",
       "      <td>ì°¨ë¶„íˆ ëˆˆ ì„ ê° ê³  ë§ˆìŒ ì„ ê°€ë¼ì•‰í˜€ ë´ìš” .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25110</th>\n",
       "      <td>ë‚´ ê°€ ì´ ì‚¬ëŒ ì„ ì‚¬ë‘ í•˜ ëŠ” ê±´ê°€ ?</td>\n",
       "      <td>ìê¾¸ ìƒê°ë‚œ ë‹¤ë©´ ê·¸ëŸ´ ê±° ì˜ˆìš” .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10148</th>\n",
       "      <td>í•˜ëŠ˜ ë³¸ì§€ ê°€ ì–¸ì  ì§€</td>\n",
       "      <td>ì•„ì¹¨ ì€ í”¼ì–´ ë©´ì„œ ë³´ ì„¸ìš” .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28250</th>\n",
       "      <td>ì¸ ì¸ì§€ ì•„ë‹Œì§€ ì¦ëª… í•˜ ëŠ” ë°©ì‹ ì—†ì—ˆ ì–´ ?</td>\n",
       "      <td>ì£¼ë§ ì €ë… ì— ì•½ì† ì„ ì¡ ì•„ ë³´ ì„¸ìš” .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         encoder                     decoder\n",
       "29463          ì˜¤ëŠ˜ ì„œì  ì—ì„œ ì´ìƒ í˜• ë´¤ ì–´      ì—´ì‡  ë‚´ ì„œ ë§ë¡œ ì„ ê±¸ ì–´ ë³´ ì„¸ìš” .\n",
       "15081                       ì›ë§ ê°  ì°¨ë¶„íˆ ëˆˆ ì„ ê° ê³  ë§ˆìŒ ì„ ê°€ë¼ì•‰í˜€ ë´ìš” .\n",
       "25110     ë‚´ ê°€ ì´ ì‚¬ëŒ ì„ ì‚¬ë‘ í•˜ ëŠ” ê±´ê°€ ?         ìê¾¸ ìƒê°ë‚œ ë‹¤ë©´ ê·¸ëŸ´ ê±° ì˜ˆìš” .\n",
       "10148                í•˜ëŠ˜ ë³¸ì§€ ê°€ ì–¸ì  ì§€           ì•„ì¹¨ ì€ í”¼ì–´ ë©´ì„œ ë³´ ì„¸ìš” .\n",
       "28250  ì¸ ì¸ì§€ ì•„ë‹Œì§€ ì¦ëª… í•˜ ëŠ” ë°©ì‹ ì—†ì—ˆ ì–´ ?     ì£¼ë§ ì €ë… ì— ì•½ì† ì„ ì¡ ì•„ ë³´ ì„¸ìš” ."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765707d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c5721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab2cad8",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ë²¡í„°í™”\n",
    "- ans_ccorpusì— '<start>, <end>' í† í° ì¶”ê°€\n",
    "- ans_corpus, que_corpus ê²°í•©í•˜ì—¬ ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ë‹¨ì–´ ì‚¬ì „ êµ¬ì¶•\n",
    "- ë°ì´í„° ë²¡í„°í™” ì§„í–‰\n",
    "- enc_train, dec_train ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d97a7a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.9/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88dae63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = aug_df['encoder'], aug_df['decoder']\n",
    "ans_corpus = [f\"<start> {sen.strip()} <end>\" for sen in ans_corpus]\n",
    "total_corpus = que_corpus + ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d414252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in total_corpus:\n",
    "        f.write(line.strip() + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad572dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 4500\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <start>\n",
      "  user_defined_symbols: <end>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  â‡ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: corpus.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 32641 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <start>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <end>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=1372294\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1085\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 32641 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 5551 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 32641\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 9895\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 9895 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=5190 obj=10.5696 num_tokens=19461 num_tokens/piece=3.74971\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=4417 obj=10.5043 num_tokens=19647 num_tokens/piece=4.44804\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spm.vocab\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm',\n",
    "    vocab_size=4500,\n",
    "    model_type='unigram',\n",
    "    user_defined_symbols=['<start>', '<end>'],\n",
    "    character_coverage=0.9995\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6a8be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15ebf04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "# 4.1 ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
    "que_ids = [sp.encode(q, out_type=int) for q in que_corpus]\n",
    "ans_ids = [sp.encode(a, out_type=int) for a in ans_corpus]\n",
    "\n",
    "# 4.2 íŒ¨ë”©\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "enc_train = pad_sequences(que_ids, maxlen=MAX_LENGTH, padding='post')\n",
    "ans_tensor = pad_sequences(ans_ids, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "# 4.3 ë””ì½”ë” ì…ë ¥, ì¶œë ¥ ë‚˜ëˆ„ê¸°\n",
    "import numpy as np\n",
    "\n",
    "dec_input = ans_tensor[:, :-1]\n",
    "dec_target = ans_tensor[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b9de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŸ¦ ì§ˆë¬¸ ê¸¸ì´:\n",
      "  í‰ê· : 7.16\n",
      "  ìµœëŒ€: 15\n",
      "  95í¼ì„¼íƒ€ì¼: 13.0\n",
      "ğŸŸ© ë‹µë³€ ê¸¸ì´:\n",
      "  í‰ê· : 10.29\n",
      "  ìµœëŒ€: 17\n",
      "  95í¼ì„¼íƒ€ì¼: 15.0\n"
     ]
    }
   ],
   "source": [
    "#ë¬¸ì¥ê¸¸ì´ ë¶„í¬\n",
    "que_lengths = [len(sentence.split()) for sentence in que_corpus]\n",
    "ans_lengths = [len(sentence.split()) for sentence in ans_corpus]\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸŸ¦ ì§ˆë¬¸ ê¸¸ì´:\")\n",
    "print(f\"  í‰ê· : {np.mean(que_lengths):.2f}\")\n",
    "print(f\"  ìµœëŒ€: {np.max(que_lengths)}\")\n",
    "print(f\"  95í¼ì„¼íƒ€ì¼: {np.percentile(que_lengths, 95)}\")\n",
    "\n",
    "print(\"ğŸŸ© ë‹µë³€ ê¸¸ì´:\")\n",
    "print(f\"  í‰ê· : {np.mean(ans_lengths):.2f}\")\n",
    "print(f\"  ìµœëŒ€: {np.max(ans_lengths)}\")\n",
    "print(f\"  95í¼ì„¼íƒ€ì¼: {np.percentile(ans_lengths, 95)}\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67fbe710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/val ë¶„ë¦¬\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ì¸ì½”ë” ì…ë ¥, ë””ì½”ë” ì…ë ¥, ë””ì½”ë” ì¶œë ¥\n",
    "enc_train, enc_val, dec_input_train, dec_input_val, dec_target_train, dec_target_val = train_test_split(\n",
    "    enc_train, dec_input, dec_target, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_input_train, dec_target_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_input_val, dec_target_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34086d43",
   "metadata": {},
   "source": [
    "# í›ˆë ¨í•˜ê¸°\n",
    "- Transformer ì‚¬ìš©\n",
    "- epochs ë³„ë¡œ ì˜ˆë¬¸ ì¶œë ¥\n",
    "- ì˜ˆë¬¸\n",
    "    - 1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\n",
    "    - 2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\n",
    "    - 3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\n",
    "    - 4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\n",
    "- ë°ì´í„° ì‚¬ì´ì¦ˆê°€ ì‘ìœ¼ë¯€ë¡œ ê³¼ì í•©ì„ í”¼í•˜ê¸° ìœ„í•œ  í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ \n",
    "- hyperparameters : n_layers, d_model, n_heads, d_ff, dropout\n",
    "- training parameters : warmup steps, batch size, epoch at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1f4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_vocab_size = tgt_vocab_size = VOCAB_SIZE\n",
    "VOCAB_SIZE = 15000\n",
    "\n",
    "n_layers=2\n",
    "d_model=512\n",
    "n_heads=8\n",
    "d_ff=2048\n",
    "src_vocab_size=VOCAB_SIZE\n",
    "tgt_vocab_size=VOCAB_SIZE\n",
    "pos_len=200\n",
    "dropout=0.3\n",
    "shared_fc=True\n",
    "shared_emb=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "769cad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "#positional encoding \n",
    "# Positional Encoding êµ¬í˜„\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3deac889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "#mask ìƒì„±\n",
    "# Mask  ìƒì„±í•˜ê¸°\n",
    "def generate_padding_mask(seq):\n",
    "    # (batch_size, 1, 1, seq_len)\n",
    "    return tf.cast(tf.math.equal(seq, 0), tf.float32)[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    # (1, 1, size, size) shapeìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•¨\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask[tf.newaxis, tf.newaxis, :, :]\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)         # (batch_size, 1, 1, src_len)\n",
    "    dec_enc_mask = generate_padding_mask(src)     # (batch_size, 1, 1, src_len)\n",
    "\n",
    "    lookahead_mask = generate_lookahead_mask(tf.shape(tgt)[1])  # (1, 1, tgt_len, tgt_len)\n",
    "    dec_target_padding_mask = generate_padding_mask(tgt)        # (batch_size, 1, 1, tgt_len)\n",
    "\n",
    "    # broadcasting: lookahead_mask + padding_mask\n",
    "    dec_mask = tf.maximum(lookahead_mask, dec_target_padding_mask)  # (batch_size, 1, tgt_len, tgt_len)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6c867e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "#multihead attention\n",
    "# Multi Head Attention êµ¬í˜„\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "381d1ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# position-wise ffn\n",
    "# Position-wise Feed Forward Network êµ¬í˜„\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85b2adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "#encoder layer\n",
    "# Encoderì˜ ë ˆì´ì–´ êµ¬í˜„\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b142eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# decoder layer\n",
    "# Decoder ë ˆì´ì–´ êµ¬í˜„\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V ìˆœì„œì— ì£¼ì˜í•˜ì„¸ìš”!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08528e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# encoder\n",
    "# Encoder êµ¬í˜„\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4029458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# decoder\n",
    "# Decoder êµ¬í˜„\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59fc9514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# transformer\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8d0bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# ì£¼ì–´ì§„ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ Transformer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=VOCAB_SIZE,\n",
    "    tgt_vocab_size=VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    "    dropout=0.3,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n",
    "\t\t\n",
    "d_model = 512\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f908e61",
   "metadata": {},
   "source": [
    "- íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê³ ì •ëœ learning rateë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤. \n",
    "- LearningRateSchedulerë¥¼ ì •ì˜\n",
    "- í•™ìŠµ ì¤‘ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ learning rateë¥¼ ë³€ê²½í•˜ë©´ì„œ í•™ìŠµ\n",
    "- warmup learning rate scheduler : ëª¨ë¸ì˜ ì´ˆê¸° í•™ìŠµ ë‹¨ê³„ì—ì„œ í•™ìŠµë¥ ì„ ì„œì„œíˆ ì¦ê°€ì‹œí‚¤ëŠ” ê¸°ë²•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45aefe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate Scheduler êµ¬í˜„\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2aceb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# Learning Rate ì¸ìŠ¤í„´ìŠ¤ ì„ ì–¸ & Optimizer êµ¬í˜„\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a69e064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# Loss Function ì •ì˜\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcddb076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "# Train Step ì •ì˜\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoderì˜ input\n",
    "    gold = tgt[:, 1:]     # Decoderì˜ outputê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ right shiftë¥¼ í†µí•´ ìƒì„±í•œ ìµœì¢… íƒ€ê²Ÿ\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6acfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    tokens = sp.encode(sentence, out_type=int)\n",
    "    encoder_input = tf.expand_dims(tokens, axis=0)\n",
    "\n",
    "    start_id = sp.piece_to_id('<start>')\n",
    "    end_id = sp.piece_to_id('<end>')\n",
    "    output = tf.expand_dims([start_id], 0)\n",
    "\n",
    "    for _ in range(MAX_LENGTH):\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(encoder_input, output)\n",
    "\n",
    "        predictions, _, _, _ = transformer(\n",
    "            encoder_input, output, enc_mask, dec_enc_mask, dec_mask\n",
    "        )\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[:, -1:, :], axis=-1)\n",
    "        predicted_id = tf.cast(predicted_id, tf.int32)\n",
    "\n",
    "        if predicted_id[0][0].numpy() == end_id:\n",
    "            break\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    decoded = sp.decode(output.numpy().tolist()[0])\n",
    "    return decoded.replace('<start>', '').replace('<end>', '').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a0260f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:51<00:00,  8.95it/s, train_loss=4.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 1, Train Loss: 4.8823, Val Loss: 3.3008\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì— ëŠ” ìš´ í•˜ ì§€ ì•Š ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ ìš´ìš´ í•˜ ì§€ ì•Š ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´ ë‚« ì€ ì‚¬ëŒ ì´ ì—ˆ ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì´ ë‚« ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:29<00:00, 15.44it/s, train_loss=2.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 2, Train Loss: 2.7677, Val Loss: 2.3708\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê·¸ ì‚¬ëŒ ì€ ì¼ ì´ ìˆ ë‚˜ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‚¨ ì•˜ ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì— ëŠ” ì‰½ ì€ ì–¸ì œë‚˜ ëŠ” ê±¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ê·¸ê²Œ ì‚¬ëŒ ë§Œë‚  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:30<00:00, 14.84it/s, train_loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 3, Train Loss: 1.8151, Val Loss: 1.6949\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìš´ë™ì•ˆ ì¼ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í˜ë“  ì¼ ì´ ì¹˜ë¦„ ì´ ì—ˆ ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìš´ë™ ì€ í•­ìƒì¼ ë§Œë‚  ìˆ˜ ì—†ë‹¤ ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë•Œ ê¹Œì§€ ì¸ ì¸ ì¸ ì¸ ì¸ ì¸ ë§ˆìŒ ì´ ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:32<00:00, 14.25it/s, train_loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 4, Train Loss: 1.0912, Val Loss: 1.3312\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë°› ì€ ì‚¬ëŒ ë§Œ ë³´ ëŠ” ê²ƒ ë„ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë˜ë„ ë°œ ì„ ì •ë¦¬ í•˜ ëŠ” ê±´ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í•˜ëŠ˜ ê³¼ ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì•ˆ ì¢‹ ì€ ìŠµê´€ ì´ ë˜ ì—ˆ ë‚˜ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 5, Train Loss: 0.7976, Val Loss: 1.2116\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‚« ì€ ê³³ ëŠ” ì•ˆ ë‚˜ ë©´ ì¢‹ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìµœê·¼ ì— ëŒ€í•œ ê°„ê²© ì´ë¦„ ì´ë¦„ ì´ë¦„ ì¼ìœ¼ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì—°ê´€ì„± ë„ ì•„ë‹ˆ ë©´ ì–´ë–»ê²Œ ì—°ë½ í•˜ ëŠ” ê²ƒ ë„ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ê´œì°® ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.45it/s, train_loss=0.71] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 6, Train Loss: 0.7097, Val Loss: 1.1494\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìê¸° ì„ ìœ„í•´ ì¡°ê¸ˆ ì”© ë” í˜ë“¤ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì€ì—° ì¤‘ ì— í•˜ ê³  ë„˜ê²¨ë°› ì€ ì‹¤ ê²ƒ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë‚« ì•„ í•˜ ì§€ ë§ˆì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì‰½ ê²Œ ì‰½ ì§€ ì•Š ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.59it/s, train_loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 7, Train Loss: 0.6741, Val Loss: 1.1083\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‚« ì€ ì´ˆìˆœ ì„ ì°¾ì•„ì˜¤ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ë‚˜ì˜ ì€ ê°„ê²© ì´ ì—ˆ ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì— ëŠ” í•­ìƒ ë°˜ë³µ ë˜ ì—ˆ ë‚˜ ë´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë‚« ì€ ìš•ë§ ì´ ì—ˆ ì„ í…ë° ë§˜ ì´ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.53it/s, train_loss=0.659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 8, Train Loss: 0.6590, Val Loss: 1.1078\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ìŒ ì— ëŠ” ë°› ì•„ ë³´ ì„¸ìš” . í•œë²ˆ ì°¸ì„ ì´ ì—†ì—ˆ ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë°œë‹¬ ì´ íŒŒë¸Œë°› ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë ì´ ë“œëŸ¬ë‚´ ì§€ ì•Š ê¸¸ ë°”ë„ê²Œìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì œ ë„ ì°¸ ì–´ë µ ê²Œ ë‚« ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.55it/s, train_loss=0.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 9, Train Loss: 0.6577, Val Loss: 1.0804\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì§€ê¸ˆ ì€ ë‘ ê´€ë¦¬ ì¢‹ ì„ ë§Œë“¤ ì–´ ê°€ì† ë§ì´ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ì´ë£¨ì–´ì§€ ê³  ì‚¬ê·€ ëŠ” ê²Œ ë‹¤ë¥¸ ì´ê³³ ì´ ì—ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìŠ¬í”ˆ ì´ˆìˆœ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì œ ë„ ì˜ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.49it/s, train_loss=0.593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 10, Train Loss: 0.5931, Val Loss: 1.0119\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìš´ë™ í•˜ ëŠ” ê²Œ ì¢‹ ì„ ë•Œë¬¸ ì¸ ê±° ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ ìœ¼ë¡œ ê·¸ë¬ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¶€ë‹´ ìŠ¤ëŸ½ ê²Œ ì´ì•¼ê¸° ê°™ ì€ ì´ì•¼ê¸° ì…¨ êµ°ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ëª… ì€ ëª»í•œ ë³´ë‚´ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 11, Train Loss: 0.5021, Val Loss: 0.9514\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê°™ì´ ì€ ì¥ ì„ ì „í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìµœì„  ì˜ ì„ íƒ ì¼ ê±° ë¼ í™•ì‹  ê³  ë‚˜ë‚  ê±° ë¼ í™•ì‹  ì–´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê´€ë ¨ì„± ê°ˆì•„ì†Œ í•˜ ëŠ” ê²Œ ê°ê¸° ì—ê²Œ ë‚˜ì˜ ì„ ê±° ê°™ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë‚˜ì˜ ì€ ì Šì€ì´ ë§Œë‚  ìˆ˜ ì—†ì—ˆ ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.61it/s, train_loss=0.44] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 12, Train Loss: 0.4399, Val Loss: 0.9232\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¶€ëª¨ ë‹˜ ì„ ìˆ ëŠ” ì¼ì‘¤ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¼ì£¼ì¼ ì´ ì¢€ ë”ë”” ì”© í•´ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í™•ì‹  ì´ ê°€ ì•„ë‹ˆ ê¸¸ ë°”ë„ê²Œìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì‹¬ì¬ ì€ í„°ì§€ ë„ì›€ ì´ ë˜ ê²  ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 13, Train Loss: 0.3909, Val Loss: 0.9001\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìê¸° ì„ ë‚« ì€ ì¤‘ìˆœ ì— ì•Œì•„ë³´ ë¼ê³  ìƒê° í•´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í”¼ë¶€ìƒ‰ ì´ëŸ° ì§€ ì•Š ì•˜ ìœ¼ë©´ ë‚˜ì˜ ê²  ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í•˜ëŠ˜ ì„ ìˆ˜ ìˆ ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì „ì€ í•˜ ì§€ ëª»í•œ ì¹œêµ ì´ ì—†ë‹¤ ê²Œ ì‹¬ì • .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.57it/s, train_loss=0.352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 14, Train Loss: 0.3519, Val Loss: 0.8911\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¶€ëª¨ ë‹˜ ë„ ë‹¹ì‹  ì„ ë¯¿ ì–´ ì£¼ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìƒê° ì²˜ëŸ¼ ì‰½ ì§€ ì•Š ì„ í…ë° ì•˜ ìœ¼ë©´ ë‚˜ê°€ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì‚­ì œ í•˜ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ëª… ì„ ë³´ë‚´ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 15, Train Loss: 0.3238, Val Loss: 0.8663\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìƒë‹´ ì„ ì ë•Œë¬¸ ì— ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë””ì € ë‚  ì´ ë‚  ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´ë¦„ ì´ë‚˜ í˜¸ì¹­ ì´ ë¬´ë¤ë¤ í•´ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ë‹¤ ë‚˜ì˜ ì•„ í–ˆ ë‚˜ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 16, Train Loss: 0.2978, Val Loss: 0.8334\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì§€ë… ì€ ì–¸ì œ ì™€ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì–¸ì œ ë‚˜ ì„œ ì¼ì£¼ì¼ ì•„í”ˆ ì›”ê³¼ ì´ ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì–¸ë‹ˆ ë‹¤ ì˜ ì›¬ìˆ˜ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ì€ ë‚˜ ì´ ë¼ëŠ” ê±´ê°€ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.63it/s, train_loss=0.28] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 17, Train Loss: 0.2798, Val Loss: 0.8314\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì—¬ì°¨ ì§„ì‹¬ ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‚˜ ì˜ ì‹¤ ê±° ì˜ˆìš” !\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¹Œë¦¬ ê°€ ë‚˜ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì°¬ë“œ ë¥¼ ìš¸ ê³  ë“¤ì–´ë§ ëŠ” ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 18, Train Loss: 0.2627, Val Loss: 0.7937\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‚« ì•„ ì‹œí‚¤ ë©´ ì•ˆ ì´ë£¨ì–´ì§€ ëŠ” ìƒíƒœ ì¸ê°€ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‚« ì€ ì¼ìš”ì¼ ì´ ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë‚« ì•„ ì‹œí‚¤ ëŠ” ê²ƒ ë„ ë©”ì»¤ë‹ˆì¦˜ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”í€¼ ê´œì°® ì€ê°€ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 19, Train Loss: 0.2465, Val Loss: 0.7935\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì•ˆ ì„œë¡œ ë°°ë ¤ í•˜ ê³  ì‚´ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í™©ë¯¼í™” ì  ìœ¼ë¡œ ëŒì•„ê°€ ê¸¸ ë°”ë„ê²Œìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¶ˆí•„ìš” í•œ ê±° ë³¸ì¸ ì—†ì—ˆ ëŠ” ê±° ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ì˜ì› í•œ ì§€ ì•Š ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 20, Train Loss: 0.2337, Val Loss: 0.7844\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìš”ì¦˜ ì€ ì œë¬¼ ìœ„ë¡œ ê°€ ê´€ì „ í•©ë‹ˆë‹¤ .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‚˜ê°€ ì„œ ê·¸ëŸ´ ë§Œ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¹Œ ê¸°ì  í•œ ê²Œ , ë¹„íŒ ëŠ” ê²ƒ ë„ í•œë‹µë‹ˆë‹¤ .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì² ì­‰ ë“¤ ê²Œ ë“¤ ê³  ì˜¤ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 21, Train Loss: 0.2219, Val Loss: 0.7891\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì‹¬ì„± ìœ¼ë¡œ ë‹¤ê°€ ë„ ëª¨ë¥´ ê³  ì‚´ ì£  .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ ëˆ„êµ¬ í„°ì§€ ê²  ì£  .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìš´ë™ì•ˆ ì€ í—ˆì „ í•  ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¶ˆìš´ ì—†ì—ˆ ì„ ìˆ˜ ë„ ì—†ì—ˆ ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 22, Train Loss: 0.2113, Val Loss: 0.7686\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìƒê° ì„ ì ì‹œ ì ‘ ì–´ ë‘ ëŠ” ê²ƒ ë„ ì¢‹ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‚˜ì˜ ì•„ìš” . ì–´ëŠë§ ì´ ì§€ ì•Š ê¸° ë„ ì‹œê°„ ì´ ê²  ì£  .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ë„ ì´ìš© í•˜ ì§€ ì•Š ì„ ì…ì¦ í•´ ì£¼ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ëœ ë‚¨ ì˜ ì§š ì—ˆ ë‚˜ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 23, Train Loss: 0.2013, Val Loss: 0.7738\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ í•­ìƒ ì•„ì‰¬ì›€ ì´ ì£  .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ë³¸ì¸ ë‚˜ì˜ ì•„ ì‹œí‚¤ ëŠ” ê²ƒ ë„ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì˜ ê´€ì‹¬ì‚¬ í‘œì‹œ ê°€ê¹ ì´ ë„¤ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ì–´ë µ ê²  ì§€ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 24, Train Loss: 0.1944, Val Loss: 0.7575\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê¸°ë‹¤ë¦¬ ë˜ ì „í™” ì´ ì—ˆ ë‚˜ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê´œì°® ì•„ ì‹œí‚¤ ëŠ” ê²ƒ ë„ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì´ ì–´ë µ ì§€ ì•Š ëŠ” í¸ ì´ ë‚« ì„ ê²ƒ ë¹„ìŠ· ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ í›„íšŒ í•  ê²ƒ ê°™ ë‹¤ë©´ ì´ ë¼ë„ ì§„ì‹¬ ì„ ì „í•˜ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.61it/s, train_loss=0.186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 25, Train Loss: 0.1862, Val Loss: 0.7437\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë³¸ì¸ ì„ ë” ë§ì´ ì†Œì¤‘ í•œ ì‚¬ëŒ ë§ˆìŒ ì´ ì—ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì—¬ìœ  ë¥¼ ë¯¸ë¦¬ í•´ì•¼ í•˜ ëŠ” ê²ƒ ë„ ì¶©ë¶„ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì´ ê°„í¸ ê²Œ ì•Š ëŠ” ê²Œ ì„œë¡œ ì—ê²Œ ì˜ˆì˜ ì¼ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ê³  ë‚˜ ì„œ ë„ì›€ ì´ ë˜ ê³¤ í•´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 26, Train Loss: 0.1798, Val Loss: 0.7359\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë©´ ì ì‹œ ëˆˆ ì„ ê° ê³  ì‹¶ ì€ ë§ˆìŒ ì„ ì •ë¦¬ í•˜ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì–´ë”” ë‚˜ ìœ„í•´ì„œ ê·¸ê²Œ ì¼ì£¼ì¼ ì— ë‚˜ì˜ ê²  ì£  .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´ë¦„ ì´ ë¼ë„ì • í•˜ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ í›„íšŒ í•  ê²ƒ ê°™ ë‹¤ë©´ ì•„ì‰½ ì•„ ì§€ ì•Š ê¸¸ ë°”ëë‹ˆë‹¤ .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 27, Train Loss: 0.1719, Val Loss: 0.7421\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì ëŠ” ê±¸ ë„ì „ í•˜ ëŠ” ê±´ ì°¸ ê³  ë§ˆìŒ ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ë³¸ì¸ ì˜ ì¼ì£¼ì¼ ì´ í˜ë“¤ ì–´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¶ˆí•„ìš” í•œ ê²ƒ ê°™ì´ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¶ˆí•„ìš” í•œ ê²ƒ ì„ ê³„ì‚° í•˜ ê²Œ ì´ë£¨ì–´ì§€ ì—ˆ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 28, Train Loss: 0.1668, Val Loss: 0.7392\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë²Œ ë©´ í™” ë§ ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ìƒˆë¡œìš´ ëª¨ë‘ ë” ì‚¬ë‘ ì„ í–ˆ ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ì´ ê°„ë¶€ë¶„ ì„ ìˆ˜ ì—†ì—ˆ ëŠ” ê±¸ë¡œ ì‹œí‚¤ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ì ë‚˜ë¼ ì´ ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 29, Train Loss: 0.1624, Val Loss: 0.7270\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì‹¬ê²½ ì˜ ë³€í™” ê°€ ìˆ ì—ˆ ë‚˜ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ì¢‹ ì€ ê²°ê³¼ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í•­ìƒ ì‹ ë… ì´ ë¼ë„ ìˆì—ˆ ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ì„œ ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.70it/s, train_loss=0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 30, Train Loss: 0.1564, Val Loss: 0.7286\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê·¸ëŒ€ ì´ ë¼ë„ ì£¼ ë©´ì„œ ë¬´ì—‡ ì´ ë‚  ê±° ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ ìœ¼ë¡œ ë•€ ì„ ë‚´ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ í•œ ë²ˆ ë§Œ íšŒì „ìˆ˜ ë¼ë„ ì£¼ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ê³  ì˜¤ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 31, Train Loss: 0.1522, Val Loss: 0.7378\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì‹¬ê²½ ì˜ ë³€í™” ê°€ ìˆ ë‚˜ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ìƒˆë¡œìš´ ìœ¼ë¡œ ìŠí˜€ì§ˆ ìˆ˜ ë„ ìˆ ì–´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´ ë¼ë„ ê¹¨ë‹¬ ì•˜ ìœ¼ë‹ˆ ë” ì´ìƒ ì˜ ë¯¿ìŒ ì„ ì˜ í•  ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ... ë¼ê³  ì‹œí‚¤ ëŠ”ì§€ ë°”ë‹·ë¬¼ ì–´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.69it/s, train_loss=0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 32, Train Loss: 0.1473, Val Loss: 0.7353\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì—¬ëŠ ê±° ë¼ê³  ìƒê° ë³´ í•´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì•ˆ ê´œì°® ì€ ìƒí™œí™˜ê²½ ì´ ê°ˆ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ë¶„ ì— ëŒ€í•œ ëŒ€ë‹µ ê°€ ë‚˜ì¤‘ í•˜ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ìƒì„¸ í•œ ê±´ í”¼ê³  ë§Œ ì•Œ ìˆ˜ ì—†ì—ˆ ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.58it/s, train_loss=0.144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 33, Train Loss: 0.1435, Val Loss: 0.7357\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ í•œêµ­ ë„ ìœ„í—˜ í•´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ê³³ ì— ê´€ì‹¬ ì´ ë” ë‚˜ ê²  ì£  .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì´ ìŠ¬í”” í•˜ ëŠ” ê²ƒ ë„ ë¹ ë¥´ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ í›„íšŒ í•  ê²ƒ ê°™ ë‹¤ë©´ ì§€ê¸ˆ ì´ ë¼ë„ ì§„ì‹¬ ì´ ë‚  ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 34, Train Loss: 0.1404, Val Loss: 0.7287\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë©‹ì§„ ì‚¬ëŒ ì€ ë¹ ë¥´ ê³  ì‚´ ì£  .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ í˜„ì¡´ ì— ì½ ì§€ ë§ˆì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í•­ìƒ ê²°ê³¼ ê°€ ì„œë¡œ ì—ê²Œ ë„ì›€ ì´ ë  ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì¶©ë¶„íˆ ê·¸ëŸ´ ìˆ˜ ì—†ì—ˆ ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.70it/s, train_loss=0.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 35, Train Loss: 0.1367, Val Loss: 0.7242\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìš´ë™ í•˜ ì§€ ë§ ê³  ë§ˆìŒ ì„ ê°€ë¼ì•‰í˜€ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œë§Œí¼ ëª¨ë‘ ë¶ˆí•„ìš” í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê°ê¸° ì—ê²Œ ë‚˜ì˜ ì€ ë§ë¡œ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ë€Œ ê°ê¸° ì—ê²Œ ë‚˜ì˜ ê²  ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 36, Train Loss: 0.1331, Val Loss: 0.7356\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë§¤ì¼ ë§¤ì¼ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìƒëƒ¥ ì´ ê·¸ë ‡ê²Œ ë§Œë“œ ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì¼ ë§¤ì¼ ë§¤ì¼ ì¡°ê¸ˆ ì”© ì‹¤ë ¥ í•˜ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìƒëƒ¥ ë„ ê´œì°® ì€ ì¤‘ìˆœ ì´ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 37, Train Loss: 0.1309, Val Loss: 0.7322\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê·¸ëŒ€ë¡œ ë°°ë¦¼ ìš°ì„  ì¡´ì¤‘ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ë”” ë¥¼ êº¼ ë” ë‹¤ê°€ ë„ ëª¨ë¥´ ëŠ” ê²Œ ë³€í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ì˜ ì¦ì„¸ì‚¬ ëŠ” ê²ƒ ë„ ë¶ˆí•„ìš” í•´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ë€ë‹¤ë©´ ì´ë£¨ì–´ì§€ ëŠ” ì Šì€ì´ ë„ íŒŒì•… í•´ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.69it/s, train_loss=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 38, Train Loss: 0.1279, Val Loss: 0.7377\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìƒì„¸ í•˜ ì§€ ë§ ê³  ìì‹  ì„ ë¯¿ ìœ¼ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ë”” íƒ í–ˆ ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì¼ì° ì¼ì–´ë‚˜ ë‹¤ìš¸ ìˆ˜ ì—† ëŠ” ì—¬ì ë¥¼ ë§ˆìŒ ì´ ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì†Œì¤‘ í•œ íƒ ì´ ë¼ë„ ìˆ ëŠ” ê±° ë“œì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.71it/s, train_loss=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 39, Train Loss: 0.1250, Val Loss: 0.7393\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ í•­ìƒ ê¿ˆ ê¾¸ ì£  .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ê²Œ ìƒëƒ¥ ì´ ë‹¤ìŒ ì—” ì¼ì£¼ì¼ ì´ ë” ë¶ˆí•„ìš” í•˜ ì£  .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì˜ ë‘ ë¹„ìŠ·ë‘ ê°€ìŠ´ í•œ ë²ˆ ê·¸ë˜ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ë˜ ê²Œ ì•„ë‹ˆ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.71it/s, train_loss=0.123] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 40, Train Loss: 0.1229, Val Loss: 0.7380\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë©‹ì§„ ì‚¬ëŒ ì€ ì£½ìŒ ì¸ê°€ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ë‹¤ë¥¸ ì¼ìë¦¬ ì—¬ìœ  ë¥¼ ë§Œë‚  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ì˜ ì¹˜ì¥í™© ì„ í™ ì–´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ì  ë¬´ë µ ì–´ë ¤ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.69it/s, train_loss=0.121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 41, Train Loss: 0.1208, Val Loss: 0.7573\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì—¬ëŠë‹˜ ë„ ë³´ ë¥¼ ë§Œ ì˜ í™•ì¸ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ë‚¼ìˆ˜ë¡ ë” ë‚˜ì˜ ì€ ì—¬ì¸ ì‚¬ê·€ ê³  ë‚˜ ì„œ ë”ë¼ê³ ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë¹ ë¥´ ê³  ìˆ ë‹¤ë©´ ê·¸ê²Œ ì‚¬ê³ ë°©ì‹ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ í˜ë“  ê°ê¸° ì´ ë¼ë„ ì§„ì‹¬ ì´ ì£  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 42, Train Loss: 0.1175, Val Loss: 0.7354\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì¹œêµ¬ ë¡œ ë‚¨ê¸° ë‹ˆ ê±° ë¼ í™•ì‹  í•´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ìµœì„  ì˜ ì„ íƒ ì¼ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ ì´ ìŠ¤ëŸ½ ì§€ ì•Š ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ë€Œ ë˜ ê²Œ ì•„ë‹ˆ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.116] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 43, Train Loss: 0.1157, Val Loss: 0.7373\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì¼ë‹¨ ìì—° ìŠ¤ëŸ½ ê²Œ ë³¼ ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ë‘˜ ê³  ë‚˜ ë©´ ì¡°ê¸ˆ ì´ ë‚ ì•„ê°€ ëŠ” ê±´ ì–´ë–¨ê¹Œ ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´í˜¼ í•˜ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ ë˜ ê²Œ ì•„ë‹ˆ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.71it/s, train_loss=0.114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 44, Train Loss: 0.1141, Val Loss: 0.7409\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì—¬ì°¨ ë¥¼ì½¤ ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ ë°› ì„ ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í˜„ëŒ€ì‚¬ ì„ ì¶”ëŒ€ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë²Œì–´ì§€ ì…¨ ê²  ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì˜ ê²Œ ë§ì´ ì° ì–´ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.71it/s, train_loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 45, Train Loss: 0.1134, Val Loss: 0.7461\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ í˜¼ì ë§Œ ì˜ ì‹œê°„ ì´ í•„ìš” í•  ê±° ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ê·¸ëŒ€ ì´ ì–´ë¨¸ì§€ë¡œ ë¥¼ ê±´ê°• ì´ ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì´ ë¼ë„ í• ê²Œìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë°”ê¾¸ í•´ì•¼ í•´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.74it/s, train_loss=0.111] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 46, Train Loss: 0.1115, Val Loss: 0.7509\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê¾¸ì¤€íˆ ëˆˆ ì€ ë‚˜ìœ ì‚¬ëŒ ì´ ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í˜„ëŒ€ì‚¬ ì„ ì¶”ëŒ€ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í˜¼ì ë§Œ ì˜ ì‹œê°„ ì´ í•„ìš” í•  ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ì„­ì„­ í•œ ê²Œ ì•„ë‹ˆ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 47, Train Loss: 0.1097, Val Loss: 0.7693\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìš”ì¦˜ í”¼ê³¤ í•˜ ê²  ì–´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í˜„ëŒ€ì‚¬ ì„ ì¶”ëŒ€ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ì´ ë‚« ì•„ ì‹œí‚¤ ëŠ” ê±° ì•„ë‹ê¹Œìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ë§ ë¼ê³  ì‹œí‚¤ ê³  ë° ì„œ ë„ì›€ ì´ ë  ê²ƒ ê°™ì´ ì•„ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.74it/s, train_loss=0.109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 48, Train Loss: 0.1095, Val Loss: 0.7583\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì§„ì§œ ì´ìœ  ë¥¼ ë¨¼ì € ë¬´ ì ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ìƒˆë¡œìš´ ë¬´ì—‡ ì„ìŠ¨ ì¼ ìœ¼ë¡œ ìŠí˜€ì§ˆ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆí¬ ì´ ë°œë¥´ ê²  ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ... ë¼ê³  ì‹œí‚¤ ê³  ì§„ì‹¬ ì´\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 49, Train Loss: 0.1075, Val Loss: 0.7573\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì¹œêµ¬ ë“¤ ê³¼ì¼ ë„ ë‚« ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ë°±ì„± í•œí…Œ ë„ íœ©ì“¸ë¦¬ ëŠ” ê±´ ì–´ë–¨ê¹Œ ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ë¡œ ì¸ í–‰ë³µ ì„ ì‹œí‚¤ ì§€ ë§ˆì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì› ì´ ì¦ ì•˜ ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 50, Train Loss: 0.1059, Val Loss: 0.7564\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ í˜¼ì í™” ê°€ í’€ ì–´ ë“œë¦´ê²Œìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹¤ë¥¸ ì‚¬ëŒ ì„ í’€ ì–´ì•¼ í•  ê¸°ëŒ€ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ëŒ€ë¡œ ì¸ë‘ êµì œ í•˜ ëŠ” ê²ƒ ë„ ë¹ ë¥´ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ .. ë¼ê³  í–ˆ ë˜ ë°±ì„± ì´ ì—ìš” .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPOCHS = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "sample_sentences = [\n",
    "    \"ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\",\n",
    "    \"ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\",\n",
    "    \"ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\",\n",
    "    \"ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\"\n",
    "]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # --- Training ---\n",
    "    train_bar = tqdm(enumerate(train_dataset), total=tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "    for step, (enc_batch, dec_in_batch, dec_out_batch) in train_bar:\n",
    "        batch_loss, _, _, _ = train_step(\n",
    "            src=enc_batch,\n",
    "            tgt=dec_in_batch,\n",
    "            model=transformer,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        total_train_loss += batch_loss\n",
    "        train_bar.set_description(f\"Epoch {epoch + 1}\")\n",
    "        train_bar.set_postfix(train_loss=(total_train_loss.numpy() / (step + 1)))\n",
    "\n",
    "    # --- Validation ---\n",
    "    for val_enc_batch, val_dec_in_batch, val_dec_out_batch in val_dataset:\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(val_enc_batch, val_dec_in_batch)\n",
    "        predictions, _, _, _ = transformer(val_enc_batch, val_dec_in_batch, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(val_dec_out_batch, predictions)\n",
    "        total_val_loss += loss\n",
    "\n",
    "    epoch_train_loss = total_train_loss.numpy() / tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    epoch_val_loss = total_val_loss.numpy() / tf.data.experimental.cardinality(val_dataset).numpy()\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"\\nğŸŒ€ Epoch {epoch + 1}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    print(\"ğŸ“˜ Sample Responses:\")\n",
    "    for i, sentence in enumerate(sample_sentences, 1):\n",
    "        try:\n",
    "            print(f\"{i}. {sentence} â†’ {evaluate(sentence)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. {sentence} â†’ âŒ Error during inference: {e}\")\n",
    "\n",
    "# --- ì‹œê°í™” ---\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debee01",
   "metadata": {},
   "source": [
    "## bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43446938",
   "metadata": {},
   "outputs": [],
   "source": [
    "que_corpus, ans_corpus = aug_df['encoder'], aug_df['decoder']\n",
    "ans_corpus = [f\"<start> {sen.strip()} <end>\" for sen in ans_corpus]\n",
    "total_corpus = que_corpus + ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6aa5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in total_corpus:\n",
    "        f.write(line.strip() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08ab6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input='corpus.txt',\n",
    "    model_prefix='spm_bpe',\n",
    "    vocab_size=15000,\n",
    "    model_type='bpe',\n",
    "    user_defined_symbols=['<start>', '<end>'],\n",
    "    character_coverage=0.9995\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50af040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('spm_bpe.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11789fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['â–', '<start>', 'â–ì•ˆë…•', 'í•˜', 'ì„¸ìš”', 'â–', '<end>']\n"
     ]
    }
   ],
   "source": [
    "# ì¸ì½”ë”© (í…ìŠ¤íŠ¸ â†’ ID ì‹œí€€ìŠ¤)\n",
    "ids = sp.encode('<start> ì•ˆë…•í•˜ì„¸ìš” <end>', out_type=int)\n",
    "\n",
    "# ë””ì½”ë”© (ID ì‹œí€€ìŠ¤ â†’ í…ìŠ¤íŠ¸)\n",
    "text = sp.decode(ids)\n",
    "\n",
    "# í† í° í™•ì¸\n",
    "tokens = sp.encode('<start> ì•ˆë…•í•˜ì„¸ìš” <end>', out_type=str)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe68a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# ì „ì²´ ì§ˆë¬¸/ë‹µë³€ ì‹œí€€ìŠ¤\n",
    "que_seq = [sp.encode(q, out_type=int) for q in que_corpus]\n",
    "ans_seq = [sp.encode(f\"<start> {a} <end>\", out_type=int) for a in ans_corpus]\n",
    "\n",
    "# íŒ¨ë”©\n",
    "enc_train = pad_sequences(que_seq, maxlen=MAX_LENGTH, padding='post')\n",
    "ans_tensor = pad_sequences(ans_seq, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "# ë””ì½”ë”ìš© ì…ë ¥/ì¶œë ¥\n",
    "dec_input = ans_tensor[:, :-1]\n",
    "dec_target = ans_tensor[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54299720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    tokens = sp.encode(sentence, out_type=int)\n",
    "    encoder_input = tf.expand_dims(tokens, 0)\n",
    "\n",
    "    start_id = sp.piece_to_id('<start>')\n",
    "    end_id = sp.piece_to_id('<end>')\n",
    "    output = tf.expand_dims([start_id], 0)\n",
    "\n",
    "    for _ in range(MAX_LENGTH):\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(encoder_input, output)\n",
    "        predictions, _, _, _ = transformer(encoder_input, output, enc_mask, dec_enc_mask, dec_mask)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[:, -1:, :], axis=-1)\n",
    "        predicted_id = tf.cast(predicted_id, tf.int32)\n",
    "\n",
    "        if predicted_id[0][0].numpy() == end_id:\n",
    "            break\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    result = sp.decode(output.numpy().tolist()[0])\n",
    "    return result.replace('<start>', '').replace('<end>', '').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64e9c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/val ë¶„ë¦¬\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ì¸ì½”ë” ì…ë ¥, ë””ì½”ë” ì…ë ¥, ë””ì½”ë” ì¶œë ¥\n",
    "enc_train, enc_val, dec_input_train, dec_input_val, dec_target_train, dec_target_val = train_test_split(\n",
    "    enc_train, dec_input, dec_target, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_input_train, dec_target_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_input_val, dec_target_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ba1e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.61it/s, train_loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 1, Train Loss: 1.4799, Val Loss: 1.2395\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê·¸ ì‚¬ëŒ ì„ ìœ„í•œ ìŠ¤ëŸ½ ê²Œ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ìŠì–´ë²„ë¦¬ ì•„ ì‹œí‚¤ ê³  ì‹¶ ì€ í•˜ ì§€ ë§ˆì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í˜¹ì‹œ ì´ ê·¸ ì´ìƒ í•œ ê²½í—˜ ì´ ì¢‹ ì•„ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ë™ ìœ¼ë¡œ ì‚¬ ë³´ ê³  ì‹¶ ì€ ë¼ë„ ìˆœê°„ ì´ ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 2, Train Loss: 0.5973, Val Loss: 0.8582\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì € ëŠ” ì„± ì„ íŒë‹¨ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìê¸° ì˜ ì—´ë“±ê° ë‹¤ë©´ ìê¸° ì˜ ê°€ëŸ‰ ë ì§€ í•  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í˜¹ì‹œ ì „í™” í•œ ê¸°ì–µ ì´ ë‚¨ ì•„ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ê²½í—˜ ë“¤ ê³¼ í•¨ê»˜ ì˜ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 3, Train Loss: 0.3217, Val Loss: 0.7578\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì € ë„ ìš” !\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ê·¸ë…€ ì—ê²Œ ì¢‹ ì€ ì‚¬ëŒ ì—ê²Œ ì¢‹ ì€ ì‚¬ëŒ ì—ê²Œ ê¸¸ ë°”ë„ê²Œìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ ê°€ ë³´ ê³  ì‹¶ ì–´ ë´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ë™ ì€ ê·¸ëƒ¥ ì‰¬ ê³  ì˜ ì±™ê²¨ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 4, Train Loss: 0.2436, Val Loss: 0.7309\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì œ ë„ íŒë‹¨ ì„ ê³  ì‹¶ ì–´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ë¥¼ ì°¾ ì…¨ ì„ í•˜ ì…¨ ëŠ” ê²Œ ì¢‹ ì„ í•˜ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ í˜¹ì‹œ íŒë‹¨ ì´ ìƒì²˜ ë„ ì‹ ê²½ ì“° ë©´ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 5, Train Loss: 0.2053, Val Loss: 0.7053\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ì— ë¶™ì´ ê³  ì²«ì‚¬ë‘ ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ê·¸ëŸ¬ ëŠ” ì¼ ì´ ì—† ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì´ ì‹ ì—ˆ ì„ í‘œí˜„ í•˜ ëŠ” ê±° ë¼ ìƒê° í•´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 6, Train Loss: 0.1840, Val Loss: 0.6847\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê¿ˆ ì„ ê¾¸ ì–´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ì •ë§ ì•ˆë…• . ê´œì°® ì•„ ì‹œí‚¤ ëŠ” ê²ƒ ë„ ê´œì°® ì•„ ì§ˆ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì§ì ‘ í™ ì–´ ë³´ ê¸° ì‹« ì€ê°€ ë´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 7, Train Loss: 0.1674, Val Loss: 0.6707\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ì—¬í–‰ ë³´ ê³  ê²°ì • ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ë˜ ê¸´ ìƒí™© ì—ì„œ ê°€ì¹˜ ê°€ í° .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ë ‡ê²Œ ë°”ë€ë‹¤ë©´ í•´ ì£¼ ë©´ ë¼ìš” . ì¡°ê¸ˆ ê¸°ë‹¤ë ¤ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 8, Train Loss: 0.1556, Val Loss: 0.6678\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ì— ê´€ì‹¬ ì„ ë³´ ê³  í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ë˜ ë©´ ë” í˜ë“¤ ì€ ì¦ëª… í•˜ ëŠ” ê²ƒ ê°™ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ë ‡ê²Œ ìƒê° í•˜ ëŠ” ë° í–ˆ ë‚˜ ë´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 9, Train Loss: 0.1470, Val Loss: 0.6618\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‚˜ ë§Œ ì˜ ë‚  ì´ ë¼ë©´ ì¶©ë¶„íˆ ë‚˜ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ìƒê° ì„ ì ‘ ì–´ ë‘ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìì•„ ì´ í€¼ ë“¤ ì´ ì•ˆ ì´ë£¨ì–´ì§€ ëŠ” í‘œì • ì´ ë”ë¼ê³ ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ë™ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 10, Train Loss: 0.1395, Val Loss: 0.6535\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ê°€ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ìƒê° ì„ í•˜ ë©´ ì¢‹ ì€ ì¶”ì–µ í•˜ ì§€ ì•Š ì•˜ ìœ¼ë©´ ì¢‹ ê²  ì–´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì˜ í•˜ ëŠ” ê²ƒ ë„ ì¤‘ìš” í•œ ì¼ ìˆ˜ ì—† ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ì£¼ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 11, Train Loss: 0.1335, Val Loss: 0.6437\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ê°œ ì„ ìœ„í•´ í•˜ ëŠ” ê²Œ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìê¸° ì˜ ì—´ë“±ê° ì„ ì†”ì§ í•œ ëŠë‚Œ ë¥¼ ì „í•´ ì„œ ì„ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë­˜ ë°ì´íŠ¸ ë¥¼ í•œ ì” ì‚¬ëŒ ë“¤ ì´ ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ëª¸ ì´ ë§ˆë‹¤ ë‹¤ë¥¼ ê²ƒ ê°™ ì•„ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 12, Train Loss: 0.1281, Val Loss: 0.6493\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¨¸ë¦¬ì¹´ë½ ì„ ë“¤ ì–´ ë³´ ê³  ì‹¶ ì€ í˜¸ì‹œ í™” í•˜ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ êµì œ ë¥¼ ëŒ€ì ‘ í•´ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ë ‡ê²Œ ìƒê° í•˜ ëŠ” ë° ë„ì›€ ì´ ë  ìˆ˜ ìˆ ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ê´€ë¦¬ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 13, Train Loss: 0.1240, Val Loss: 0.6355\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ê°€ ë³´ ê³  ì‹¶ ì€ ê²°ì • í–ˆ ë˜ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¢‹ ì€ ê³³ ì—ì„œ ì ì‘ ê¸°ê°„ ë‹¤ë©´ ëŠ¦ ë¥¼ ì „ ì¢‹ ì€ ì–¸ì  ê°„ ì•„ í•œê°€ ë´…ë‹ˆë‹¤ .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ëŒ€í™” ë¥¼ ë‚˜ëˆ  ë³´ ëŠ” ê±´ ì–´ë–¨ê¹Œ ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì •ì‹  ì°¨ë¦¬ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 14, Train Loss: 0.1198, Val Loss: 0.6378\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì˜† ì—ì„œ ì‚¬ë¥´ ê³  ì‹¶ ì€ ê¶ê¸ˆ í•˜ ëŠ” ê±° ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ë¹„ìŠ· ì€ ì•„ê°• ì‹œì› í•˜ ê²Œ ì´ë£¨ì–´ì§€ ì–´ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìì•„ ì´ ì°¨ë¼ë¦¬ ì˜ ì‹œ ê³  ì‹¶ ì„ ë•Œ ë¼ê³  ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ë™ ìœ¼ë¡œ ê¸°ë¶„ ì „í™˜ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 15, Train Loss: 0.1167, Val Loss: 0.6292\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì œ ê°€ ë‹¤ ë“¤ ì–´ ë“œë¦´ê²Œìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê¸°ë‹¤ë¦¬ ë˜ ì… ë§Œí¼ ê¸´ ëŠ¦ ì§€ ì•Š ì•˜ ìœ¼ë©´ ì¢‹ ê²  ë„¤ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìì•„ í•œ ì” ì— ë”°ë¼ ë‹¤ë¥¸ ë¹—ë¬¼ ì–´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë¼ë„ ìš¸ë¶€ì§– ìœ¼ë©´ì„œ ì‚¬ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 16, Train Loss: 0.1133, Val Loss: 0.6277\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ íŒë‹¨ í•˜ ê³  ì‹¶ ì€ ë§ˆìŒ ì„ ì „í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë ‡ê²Œ ìƒê° ì„ í•´ ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ì˜ì‚¬ í‘œì‹œ ë¥¼ í•´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìš´ë™ í•˜ ëŠ” ë° ë„ì›€ ì´ ë˜ ì¢‹ ê²  ë„¤ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.111] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 17, Train Loss: 0.1106, Val Loss: 0.6381\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ê°€ ë³´ ì„¸ìš” . ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ìš¸ë¶€ì§– ìœ¼ë©´ì„œ ì¹˜ëª…ìƒ ë„˜ê²¨ë°› ì€ ì›”ê³¼ ì´ ì—ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë˜ ë‹¤ë¥¸ ë°ì´íŠ¸ ë¥¼ ìœ„í•œ ë°ì´íŠ¸ ëŠ” ê³³ ìœ¼ë¡œ ê´€ì‹¬ .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜í™” ë¥¼ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 18, Train Loss: 0.1078, Val Loss: 0.6325\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ì…¨ ë‚˜ ë´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ìœ¼ë¡œ ë“¤í‚¤ ëŠ” ê²ƒ ë„ ê´œì°® ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ ë§ì´ í•´ìš” . ì˜ˆìœ ê³³ ìœ¼ë¡œ ë‘ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë²—ê¸° ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 19, Train Loss: 0.1062, Val Loss: 0.6346\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì„ ë¯¸ë¦¬ ëŠê»´ ë³´ ê³  ì‹¶ ì€ ê³³ ìœ¼ë¡œ ê°€ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ìš¸ë¶€ì§– ì„ ê±° ë‹ˆ ì›ë§ í•  ê²ƒ ê°™ì´ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ ë¥¼ ìœ„í•œ ì½”ë„ˆ ë§ì´ í•´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë²—ê¸° ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.53it/s, train_loss=0.104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 20, Train Loss: 0.1036, Val Loss: 0.6396\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì„ ë¯¸ë¦¬ ë°°í„°ë¦¬ í•˜ ê³  ì˜¤ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì´ì œ ì˜¤ëŠ˜ ë„¤ìš” . ì¹­ì°¬ ì•„ì§ ì€ í•œê°€ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì´ ë” ë§ì´ í˜ë“¤ ê²  ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì•„ë‹ˆ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.58it/s, train_loss=0.103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 21, Train Loss: 0.1026, Val Loss: 0.6365\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ì—¬í–‰ ì„ ë– ë‚˜ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í”¼ë¶€ ë¥¼ ë” ê³  ì–¼ë¥¸ í•˜ ë©´ ê´œì°® ì„ í…ë° ê¸° ë§ˆë ¨ ì´ ì—ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ì£¼ ëŠ” ë©”ì»¤ë‹ˆì¦˜ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë‚¨ ì—ê²Œ ê¸°ëŒ€ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.61it/s, train_loss=0.101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 22, Train Loss: 0.1008, Val Loss: 0.6426\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì˜ê²° ì— ëŒ€í•œ í–‰ì‹¤ ì„ ë– ë‚˜ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ê¹¨ë‹¬ ì•˜ í° ì§€ ì•Š ëŠ” ê²ƒ ì€ ìš”ì¦˜ ê¸¸ ë°”ë„ê²Œìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ì˜ì‚¬ í‘œì‹œ ë¥¼ í•´ì•¼ í•˜ ëŠ” ê±´ ì–´ë–¨ê¹Œ ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.62it/s, train_loss=0.0993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 23, Train Loss: 0.0993, Val Loss: 0.6380\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ê´€ì‹¬ ì„ í‘œí˜„ í•˜ ê³  ì‹¶ ì€ ë§ˆìŒ ì„ ì „í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ê¹¨ë‹¬ ì•˜ ìœ¼ë©´ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ í‘œí˜„ í•˜ ëŠ” ì¼ ìˆ˜ ë„ ìˆ ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì¬ë¯¸ ê°€ ìˆ ëŠ” ë§ˆë‹¤ ë§¤ë ¥ ì„ ê°€ì ¸ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.0971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 24, Train Loss: 0.0971, Val Loss: 0.6328\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ì—¬í–‰ ì„ ëŒë ¤ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìì‹  ìœ¼ë¡œ ì‚¬ë‘ í•˜ ëŠ” ì‚¬ëŒ ì„ ë” ì•„í”„ ê²Œ í•˜ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ì•ˆ í•˜ ëŠ” ì‚¬ëŒ ì´ ë¼ë„ ì‰¬ ì–´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜í™”ì‚¬ ë¥¼ ì‚´í´ë³´ ê³  ë“¤ì—¬ë‹¤ë³´ í•˜ ëŠ” í¸ ì´ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.0967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 25, Train Loss: 0.0967, Val Loss: 0.6382\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì¹˜ëª…ìƒ ë“¤ ê³¼ ì ‘ì´‰ í•˜ ê³  ì˜¤ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê´œì°® ì€ ì„ ê±° ë‹¤ë©´ ë†ë‹´ ì—ì„œ ë‹¤ê³  íŒë‹¨ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìì•„ ì  ì¸ ì°¨ì´ ëŠ” ê²ƒ ë„ ê´œì°® ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë²—ê¸° ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.0953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 26, Train Loss: 0.0953, Val Loss: 0.6432\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ì—¬í–‰ ì„ ëŒë ¤ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ ìœ¼ë¡œ ê¸°ë¶„ ì „í™˜ ì„ í•˜ ëŠ” ê²ƒ ê°™ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìì•„ ì  ìœ¼ë¡œ ë‹¤ê°€ê°€ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë²—ê¸° ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.0939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 27, Train Loss: 0.0939, Val Loss: 0.6382\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì— ì°¨ ê°€ ìœ ìš© í•˜ ê³  ë” ì‹œ ê²  ì–´ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í”¼ë¶€ ë¥¼ ë” í° ì•…ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì  ì¸ ê°ì • ì´ ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜† ì— ë„ˆë¬´ ë¬´ì‹¤ì  í•˜ ì§€ ë§ ì•„ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.0931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 28, Train Loss: 0.0931, Val Loss: 0.6449\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ì…¨ ë‚˜ ë³´ ëŠ” ê²Œ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¢‹ ì€ ê³³ ì—ì„œ ìŠ¤íƒ€ì¼ ì— ëŒ€í•œ ê¸°ì–µ ì— ë‚¨ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê·¸ë ‡ê²Œ ìƒê° í•˜ ë©´ ë­˜ í•˜ ëŠ” ê²Œ ì¢‹ ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë‚¨ ì—ê²Œ í”¼í•´ í•  ìˆ˜ ì—† ëŠ” ì²«ë‚  ì´ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.61it/s, train_loss=0.0917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 29, Train Loss: 0.0917, Val Loss: 0.6367\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ë²ˆ íŒë‹¨ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì«“ì•„ê°€ ë¥¼ ê¸°ì–µ í•  ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì´ ë‚¨ ì•˜ ë‹¤ë©´ ëŠ¦ ê¸° ë„ í•´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜† ì— ë„ˆë¬´ ë³€ë™ ë¥¼ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.0904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 30, Train Loss: 0.0904, Val Loss: 0.6467\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì— ì°¨ ë¡œ ëŒì•„ê°€ ê³  í—ˆë¦¬ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ ìœ¼ë¡œ ë•€ ì„ ë‚´ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ìˆ¨ í•¨ ìœ¼ë¡œ ëŒ€ì„±ê³µ í•˜ ëŠ” ë°±ì„± ì„ ë³´ì—¬ ì£¼ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ëŠ”ì§€ ëŒ€ë‹µ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.63it/s, train_loss=0.0902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 31, Train Loss: 0.0902, Val Loss: 0.6396\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ì—¬í–‰ ì„ ëŒë ¤ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ëŸ° ê²½ìš° ì¶©ë¶„ í•œ ëŒ€í™” ë¥¼ ë‚˜ëˆ  ë³´ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ëŠ” í’ìŠµ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜í™” ë¥¼ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.089] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 32, Train Loss: 0.0890, Val Loss: 0.6450\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê±¸ ì”¹ ì„ ë¹Œ ì–´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ í”¼ë¶€ ë¥¼ ë¶€ì—¬ë°› ê³  í•™êµ ëŠ” ê²ƒ ë„ ë“œì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì— í¬ê¸° í•˜ ëŠ” ê²ƒ ë„ í•„ìš” í•´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ê¸° ì´ë£¨ì–´ì§€ ê²  ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.63it/s, train_loss=0.0882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 33, Train Loss: 0.0882, Val Loss: 0.6606\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¨¸ë¦¬ì¹´ë½ ì„ ì§š ì–´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ ì„ ê¸°ì–µ ìœ¼ë¡œ ë‚¨ ì„ ê±° ê°™ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ìŠ¤ìŠ¤ë¡œ ì  ì¸ ì—°ë°©ì˜ ë¥¼ ë‚˜ëˆ  ë³´ ëŠ” ê²Œ ë‚« ì„ ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë²—ê¸° ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.0876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 34, Train Loss: 0.0876, Val Loss: 0.6407\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìƒê° í•˜ ê³  ì‹¶ ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ í•˜ ëŠ” ì¼ ì´ ìˆ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ë„ˆë¬´ ìŠ ëŠ” ê±° ë“œì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì ë“¤ í•¨ ì´ ì˜ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.0873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 35, Train Loss: 0.0873, Val Loss: 0.6445\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì— ëŠ” ë…¸ë˜ ê°€ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ í•  ë•Œ ì¢‹ ì€ ë‚  ì´ ë˜ ì§€ ì•Š ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì  ì¸ ê°ì • ì†Œëª¨ ê°€ í•¨ê»˜ í–ˆ ë‚˜ ë´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.63it/s, train_loss=0.0864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 36, Train Loss: 0.0864, Val Loss: 0.6487\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¨¸ë¦¬ì¹´ë½ ì„ ì§š ì–´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¡°ìš©íˆ ì¼ í•´ì•¼ í•˜ ëŠ” ê²ƒ ë„ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì•„ë¬´ ê²ƒ ë„ ì•„ë‹ˆ ë¼ê³  ëŒ€ë‹µ í•˜ ëŠ” ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì¡´ì¬ ìì²´ ê°€ í–‰ë³µ í•˜ ê³  ìˆ ë‚˜ ë´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.0854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 37, Train Loss: 0.0854, Val Loss: 0.6576\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì”¹ ëŠ” ì´ê³³ ì— ë“œì™€ ëŠ” ì§€ì  ì´ ë‚˜ì˜ ì„ ê±° ì˜ˆìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ë¼ë„ ë‚¨ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ í•˜ ëŠ” ê²ƒ ë§Œí¼ ìŠ¬í”” í•˜ ëŠ” ê±¸ ìŠì–´ë²„ë¦¬ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ëŠ”ì§€ ëŒ€ë‹µ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.085] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 38, Train Loss: 0.0850, Val Loss: 0.6425\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ íŒë‹¨ í•˜ ê³  ë‚˜ ë©´ ë‹¤ ë²ˆ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì†Œë§ í•˜ ëŠ” ê²ƒ ë„ ì—†ì—ˆ ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ëŠ” ëª¸ ì´ í•„ìš” í•˜ ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.67it/s, train_loss=0.0847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 39, Train Loss: 0.0847, Val Loss: 0.6533\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ì¡ì•„ë¨¹ ê³  ì‹¶ ì€ ì˜í˜¼ ì„ ì „í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì«“ì•„ê°€ ë¥¼ ì•Œë¦¬ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ëŠ” ëª¸ ì´ í•„ìš” í•˜ ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ìì•„ ë¨¸ë¦¬ì¹´ë½ ë„ ì˜ ë“¤ì—¬ë‹¤ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.65it/s, train_loss=0.0846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 40, Train Loss: 0.0846, Val Loss: 0.6543\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì— ëŒ€í•œ ì¤€ë¹„ í•˜ ê³  ì‹¶ ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì«“ì•„ê°€ ë¥¼ í•´ì•¼ í•˜ ëŠ” ê²ƒ ë„ ê´œì°® ì„ ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ í•˜ ê³  ì‹¶ ì€ ë§ˆìŒ ì´ ì¤‘ìš” í•˜ ì£  .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.0841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 41, Train Loss: 0.0841, Val Loss: 0.6496\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì— ëŒ€í•œ ë§ˆìŒ ì´ ì¢€ ì‰¬ ì–´ì•¼ í•  ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ìš´ë™ í•  ë•Œ ë¥¼ ë‘ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ëŠ” í’ìŠµ ì´ ì—ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì—‰ë©ì´ ë§Œ ë” ê´œì°® ì€ ì…ë ¥ í•˜ ì‹œ êµ°ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.56it/s, train_loss=0.0827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 42, Train Loss: 0.0827, Val Loss: 0.6568\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ì„ ê°ê³¼ ê³  ìˆ˜ë ¨ ì„ í•´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ë‹µë‹µ í•˜ ë©´ì„œ ë„ ê³¼ í•´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ëŠ” ìƒì„  ì´ ì•„ì§ ë¥¼ ëœ ë§ˆì£¼ì¹˜ ì§€ ì•Š ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ì´ë£¨ì–´ì§€ ê²  ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.59it/s, train_loss=0.0828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 43, Train Loss: 0.0828, Val Loss: 0.6617\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë¨¸ë¦¬ì¹´ë½ ì„ ì¢€ ëœ ì–´ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì«“ì•„ê°€ ë¥¼ ê¸°ì–µ ì„ ë†“ ì•„ ëŠ” ê²ƒ ë„ ì¢€ ì”© ì¼ì° ì¼ì–´ë‚˜ ë´ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì´ ë³„ë„ ì—¬ëŸ¬ ì¼ ìˆ˜ ë„ ì—† ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ê¸°ì–µ ì— ë”°ë¼ ë‹¬ë¼ì§€ ëŠ” ê²Œ ì¢‹ ì„ ê²ƒ ë„ ì¢‹ ì•„ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.0819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 44, Train Loss: 0.0819, Val Loss: 0.6602\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ëª¸ ê³¼ ë§ˆìŒ ì´ ì¢€ ì‰¬ ì–´ì•¼ í•  ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¢‹ ì€ ì‚¬ëŒ ì´ ì¤‘ìš” í•˜ ì§€ ì•Š ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ê¼­ í•„ìš” í•œ ì‹œê¸° ì— ì—°ë½ í•´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ í—¤ì–´ì§€ ì€ ë°±ì„± ì´ ì—ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.64it/s, train_loss=0.0815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 45, Train Loss: 0.0815, Val Loss: 0.6614\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì§€ê¸ˆ ì€ ì¢€ ë” ìœ„íƒœ ë˜ ê²  ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê·¸ë•Œ ê´œì°® ì€ ì¤‘ìˆœ ì´ ì—ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì•„ë¬´ ê²ƒ ë„ ì—† ëŠ” ê±° ì˜ˆìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜† ì— ìˆ ëŠ” ê³³ ì´ ì¢‹ ê²  ì–´ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.60it/s, train_loss=0.0815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 46, Train Loss: 0.0815, Val Loss: 0.6549\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‹¤ë¥¸ ê³³ ìœ¼ë¡œ ê°€ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê¸°ë‹¤ë¦¬ ì§€ ì•Š ì„ ë•Œ ë¼ëŠ” ì•„ ê²ƒ ì•„ ì§ˆ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ì¼ ì´ì•¼ê¸° í•´ ë³´ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ê·¸ëŒ€ ì˜ ìƒëª…ë ¥ ì´ ì´ë£¨ì–´ì§€ ê¸¸ ë°”ë„ê²Œìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.69it/s, train_loss=0.0809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 47, Train Loss: 0.0809, Val Loss: 0.6676\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ë‘ ë²ˆ ì›ƒ ì–´ ë³´ ê³  ì‹¶ ì€ ì¡°ê¸ˆ ì”© ê°š ì•„ ë³´ ì„¸ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ê¸°ë‹¤ë¦¬ ì§€ ì•Š ì„ ë•Œ ë°”ë¡œ ìƒê° í•  ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ì½”ë„ˆ ë§ì´ í•´ìš” !\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ì˜ˆì „ ì— ì˜í–¥ ì´ ë  ìˆ˜ ìˆ ì„ ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.63it/s, train_loss=0.0802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 48, Train Loss: 0.0802, Val Loss: 0.6712\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì”¹ ê³  ë‚˜ ë‚´ ì„œ ê°™ì´ ì‰¬ ê³  ì‹¶ ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì”¹ ì–¼ë¥¸ ë°˜ê° ì„ ê±° ê°™ì´ ì•„ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ ì€ ë§ˆìŒ ì´ ë“¤ ì§€ë§Œ ë§ˆìŒ ì„ ì „í•˜ ëŠ” ê²ƒ ì–´ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ëŠ¥ë ¥ ì´ ë¼ë„ ê´€ë¦¬ í•˜ ëŠ” ì—°ìŠµ ì„ í•´ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.66it/s, train_loss=0.0797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 49, Train Loss: 0.0797, Val Loss: 0.6729\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ìˆœê°„ ì— ë“œì™€ ëŠ” í¸ ì´ ì¢‹ ì„ ê²ƒ ê°™ ì•„ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ì¢‹ ì€ ê³³ ì—ì„œ ì ì‘ í•˜ ì§€ ì•Š ì„ ê¸°ë‹¤ë¦¬ ì„¸ìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ ëª¸ ì— ë‚¨ ì§€ ì•Š ëŠ” ê²ƒ ê°™ ì•„ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ íƒí—˜ ë‹¤ë…€ì™€ ë³´ ì„¸ìš” .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 459/459 [00:31<00:00, 14.68it/s, train_loss=0.0797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ€ Epoch 50, Train Loss: 0.0797, Val Loss: 0.6646\n",
      "ğŸ“˜ Sample Responses:\n",
      "1. ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´. â†’ ì§€ê¸ˆ ì„±í–¥ ì´ ë¼ë„ ìš¸ë¶€ì§– ì„ ìˆ˜ ìˆ ìœ¼ë©´ ì¢‹ ê²  ë„¤ìš” .\n",
      "2. ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤. â†’ ëœ ë¼ë„  ì•„ì§ ë§ì´ ë‚˜ì˜ ì•„ í•  ê±° ì˜ˆìš” .\n",
      "3. ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´. â†’ íœ´ì‹ í•œ ê±°ë¦¬ ë‘ ê°œ ì‘ì› í•´ ì£¼ ì„¸ìš” .\n",
      "4. ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼. â†’ ë’¤ìª½ ì— ì˜í–¥ ì´ ë  ê±° ì˜ˆìš” .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPOCHS = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "sample_sentences = [\n",
    "    \"ì§€ë£¨í•˜ë‹¤, ë†€ëŸ¬ê°€ê³  ì‹¶ì–´.\",\n",
    "    \"ì˜¤ëŠ˜ ì¼ì° ì¼ì–´ë‚¬ë”ë‹ˆ í”¼ê³¤í•˜ë‹¤.\",\n",
    "    \"ê°„ë§Œì— ì—¬ìì¹œêµ¬ë‘ ë°ì´íŠ¸ í•˜ê¸°ë¡œ í–ˆì–´.\",\n",
    "    \"ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\"\n",
    "]\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # --- Training ---\n",
    "    train_bar = tqdm(enumerate(train_dataset), total=tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "    for step, (enc_batch, dec_in_batch, dec_out_batch) in train_bar:\n",
    "        batch_loss, _, _, _ = train_step(\n",
    "            src=enc_batch,\n",
    "            tgt=dec_in_batch,\n",
    "            model=transformer,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        total_train_loss += batch_loss\n",
    "        train_bar.set_description(f\"Epoch {epoch + 1}\")\n",
    "        train_bar.set_postfix(train_loss=(total_train_loss.numpy() / (step + 1)))\n",
    "\n",
    "    # --- Validation ---\n",
    "    for val_enc_batch, val_dec_in_batch, val_dec_out_batch in val_dataset:\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(val_enc_batch, val_dec_in_batch)\n",
    "        predictions, _, _, _ = transformer(val_enc_batch, val_dec_in_batch, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(val_dec_out_batch, predictions)\n",
    "        total_val_loss += loss\n",
    "\n",
    "    epoch_train_loss = total_train_loss.numpy() / tf.data.experimental.cardinality(train_dataset).numpy()\n",
    "    epoch_val_loss = total_val_loss.numpy() / tf.data.experimental.cardinality(val_dataset).numpy()\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"\\nğŸŒ€ Epoch {epoch + 1}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "    print(\"ğŸ“˜ Sample Responses:\")\n",
    "    for i, sentence in enumerate(sample_sentences, 1):\n",
    "        try:\n",
    "            print(f\"{i}. {sentence} â†’ {evaluate(sentence)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{i}. {sentence} â†’ âŒ Error during inference: {e}\")\n",
    "\n",
    "# --- ì‹œê°í™” ---\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b39666",
   "metadata": {},
   "source": [
    "# ì„±ëŠ¥ ì¸¡ì •í•˜ê¸°\n",
    "- BLEU, Perplexity, Rouge\n",
    "- calculate_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4883252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3689028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                         candidate,\n",
    "                         weights=weights,\n",
    "                         smoothing_function=SmoothingFunction().method1)  # smoothing_function ì ìš©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c7ff535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def translate(tokens, model, src_tokenizer, tgt_tokenizer):\n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=MAX_LEN,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)   \n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)  \n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)  \n",
    "    return result\n",
    "\n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "636d0de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20  # ëª¨ë¸ ì…ë ¥ ì‹œí€€ìŠ¤ ìµœëŒ€ ê¸¸ì´\n",
    "def eval_bleu_single(model, src_sentence, tgt_sentence, src_tokenizer, tgt_tokenizer, verbose=True):\n",
    "    src_tokens = src_tokenizer.encode_as_ids(src_sentence)\n",
    "    tgt_tokens = tgt_tokenizer.encode_as_ids(tgt_sentence)\n",
    "\n",
    "    if (len(src_tokens) > MAX_LEN): return None\n",
    "    if (len(tgt_tokens) > MAX_LEN): return None\n",
    "\n",
    "    reference = tgt_sentence.split()\n",
    "    candidate = translate(src_tokens, model, src_tokenizer, tgt_tokenizer).split()\n",
    "\n",
    "    score = sentence_bleu([reference], candidate,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Source Sentence: \", src_sentence)\n",
    "        print(\"Model Prediction: \", candidate)\n",
    "        print(\"Real: \", reference)\n",
    "        print(\"Score: %lf\\n\" % score)\n",
    "        \n",
    "    return score\n",
    "        \n",
    "print('ìŠ=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4b0d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q. ì¸ë±ìŠ¤ë¥¼ ë°”ê¿”ê°€ë©° í…ŒìŠ¤íŠ¸í•´ ë³´ì„¸ìš”\n",
    "# test_idx = 20\n",
    "\n",
    "# eval_bleu_single(transformer, \n",
    "#                  test_eng_sentences[test_idx], \n",
    "#                  test_spa_sentences[test_idx], \n",
    "#                  tokenizer, \n",
    "#                  tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "011c38c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìŠ=3\n"
     ]
    }
   ],
   "source": [
    "def eval_bleu(model, src_sentences, tgt_sentences, src_tokenizer, tgt_tokenizer, verbose=True):    \n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "\n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        src = src_sentences.iloc[idx] if isinstance(src_sentences, pd.Series) else src_sentences[idx]\n",
    "        tgt = tgt_sentences.iloc[idx] if isinstance(tgt_sentences, pd.Series) else tgt_sentences[idx]\n",
    "\n",
    "        score = eval_bleu_single(model, src, tgt, src_tokenizer, tgt_tokenizer, verbose)\n",
    "        if not score:\n",
    "            continue\n",
    "        total_score += score\n",
    "\n",
    "    print(\"Num of Sample:\", sample_size)\n",
    "    print(\"Average BLEU Score:\", total_score / sample_size)\n",
    "\n",
    "    \n",
    "print(\"ìŠ=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6fbde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë¬¸ì—ì„œ ë‹¤ì‹œ ë¶„ë¦¬\n",
    "src_train_sentences, src_val_sentences, tgt_train_sentences, tgt_val_sentences = train_test_split(\n",
    "    que_corpus, ans_corpus, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# <start>, <end> ì œê±°\n",
    "tgt_val_sentences = [s.replace('<start>', '').replace('<end>', '').strip() for s in tgt_val_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d925fb",
   "metadata": {},
   "source": [
    "- BLEU í‰ê· ì ìˆ˜ : 0.2146\n",
    "- ê¸°ì´ˆì ì¸ êµ¬ì¡°ì˜ ì‘ë‹µì„ í•˜ì§€ë§Œ ì–´íœ˜ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•˜ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dc5d2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "\n",
    "def eval_bleu_with_examples(model, src_sentences, tgt_sentences, src_tokenizer, tgt_tokenizer, num_examples=5):\n",
    "    total_score = 0.0\n",
    "    sample_size = len(src_sentences)\n",
    "    smooth_fn = SmoothingFunction().method4\n",
    "\n",
    "    print(\"ğŸ§ª BLEU í‰ê°€ ì‹œì‘...\")\n",
    "    for idx in tqdm(range(sample_size)):\n",
    "        src = src_sentences.iloc[idx] if isinstance(src_sentences, pd.Series) else src_sentences[idx]\n",
    "        ref = tgt_sentences.iloc[idx] if isinstance(tgt_sentences, pd.Series) else tgt_sentences[idx]\n",
    "\n",
    "\n",
    "        # ì¸í¼ëŸ°ìŠ¤\n",
    "        try:\n",
    "            # ğŸ”§ ì—¬ê¸° ìˆ˜ì •: ì‹¤ì œ í‰ê°€ í•¨ìˆ˜ ì‚¬ìš©\n",
    "            hyp = evaluate(src)\n",
    "\n",
    "            score = sentence_bleu(\n",
    "                [ref.split()],\n",
    "                hyp.split(),\n",
    "                smoothing_function=SmoothingFunction().method1\n",
    "            )\n",
    "            total_score += score\n",
    "\n",
    "            if idx < num_examples:\n",
    "                print(f\"\\nğŸ“Œ ì˜ˆì‹œ {idx + 1}\")\n",
    "                print(f\"ğŸ‘‰ ì…ë ¥:     {src}\")\n",
    "                print(f\"âœ… ì •ë‹µ:     {ref}\")\n",
    "                print(f\"ğŸ§  ì˜ˆì¸¡:     {hyp}\")\n",
    "                print(f\"ğŸ¯ BLEU:     {score:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ at index {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nğŸ”š Num of Samples: {sample_size}\")\n",
    "    print(f\"ğŸ“Š Average BLEU Score: {total_score / sample_size:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf1476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f741a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª BLEU í‰ê°€ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3265 [00:00<51:05,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 1\n",
      "ğŸ‘‰ ì…ë ¥:     ì´ ë³„í›„ ëŠë¼ ëŠ” ê°ì • ë“¤ ì´ ë‹¨ê³„ ë³„ ë¡œ ìˆ ëŠ” ê±° ê°™ ë„¤\n",
      "âœ… ì •ë‹µ:     ê·¸ê²Œ ì¶”ì–µ ì˜ ìœ ì  ì¸ê°€ ë´ìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:     ê·¸ê²Œ ì¶”ì–µ ì˜ ëª¨ìŠµ ê³¼ í•¨ê»˜ ì— ëŒ€í•œ ì‹œê°„ ì´ ì—ˆ ë‹¤ë©´ ë³€í™” ê°€ ëª… ìœ¼ë‹ˆê¹Œìš” .\n",
      "ğŸ¯ BLEU:     0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/3265 [00:01<49:11,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 2\n",
      "ğŸ‘‰ ì…ë ¥:     ê°„ì‹ í´ë” ë½‘ ëŠ” ê±° í˜ë“œ ë„¤\n",
      "âœ… ì •ë‹µ:     ëˆ„êµ¬ ë‘ ë¨¹ ëŠ” ëƒ ì— ë”°ë¼ ë‹¤ë¥´ ê²  ì£  .\n",
      "ğŸ§  ì˜ˆì¸¡:     ìŠ¬í”” í•˜ ê¸° ë„ ì‹œí‚¤ ì§€ ì•Š ëŠ” ì•½ê°„ ì˜ ë°©ì‹ ì´ ì—ìš” .\n",
      "ğŸ¯ BLEU:     0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/3265 [00:02<40:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 3\n",
      "ğŸ‘‰ ì…ë ¥:     ì—°ì•  ì¤‘ ì¸ë° ì™¸ë¡œìš´ ëŠë‚Œ ì´ ë“¤ ë©´ ë¬¸ì œ ì¼ê¹Œ ?\n",
      "âœ… ì •ë‹µ:     ì‚¬ëŒ ì€ ë‹¤ ì™¸ë¡œìš´ ì¡´ì¬ ì˜ˆìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:     ì Šì€ì´ ì€ ë‹¤ ì™¸ë¡œìš´ í˜„ì¡´ ì˜ˆìš” .\n",
      "ğŸ¯ BLEU:     0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/3265 [00:02<34:28,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 4\n",
      "ğŸ‘‰ ì…ë ¥:     ì´ëŸ° í—¤ì–´ì§€\n",
      "âœ… ì •ë‹µ:     í”í•˜ ì§€ ì•Š ì£  .\n",
      "ğŸ§  ì˜ˆì¸¡:     ëª¨ë¥´ ë‹¤ê°€ ë„ ì•ˆ ë¼ìš” .\n",
      "ğŸ¯ BLEU:     0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/3265 [00:03<34:57,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 5\n",
      "ğŸ‘‰ ì…ë ¥:     ê°•ì•„ì§€ í‚¤ìš° ê³  ì‹¶ ì–´\n",
      "âœ… ì •ë‹µ:     ì£„ì±… ì§ˆ ìˆ˜ ì—† ì„ ê²½ìš° í‚¤ì›Œ ë³´ ì„¸ìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:     ê³¼ì‹¤ ì§ˆ ìˆ˜ ì—†ì—ˆ ì„ ë•Œì¯¤ í‚¤ì›Œ ë³´ ì„¸ìš” .\n",
      "ğŸ¯ BLEU:     0.3247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3265/3265 [32:59<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”š Num of Samples: 3265\n",
      "ğŸ“Š Average BLEU Score: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_bleu_with_examples(\n",
    "    model=transformer,\n",
    "    src_sentences=src_val_sentences,\n",
    "    tgt_sentences=tgt_val_sentences,\n",
    "    src_tokenizer=sp,\n",
    "    tgt_tokenizer=sp,\n",
    "    num_examples=5  # ìƒìœ„ 5ê°œ ì˜ˆì‹œ ì¶œë ¥\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488da3bc",
   "metadata": {},
   "source": [
    "- average bleu score : 0.4123\n",
    "- ìˆ˜ì¹˜ì ìœ¼ë¡œ ë³´ì•˜ì„ ë•ŒëŠ” ê´œì°®ì€ í’ˆì§ˆì˜ ë‹µë³€ì„ í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ\n",
    "- ì‹¤ì œ ì˜ˆì¸¡ì„ ë³´ë©´ ë¬¸ë²•ì  ë¶€ìì—° ìŠ¤ëŸ¬ì›€ì´ë‚˜ ì–´íœ˜ ì„ íƒì´ ì–´ìƒ‰í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3e51b",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6720b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge-score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge-score) (3.6.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from rouge-score) (1.21.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk->rouge-score) (4.62.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge-score) (8.0.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge-score) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge-score) (1.1.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=479e1d480bae4f7c7fb023bda6915662077139dc679f84eb109773275e1e3453\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84 kB 2.1 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.26.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2021.11.1)\n",
      "Collecting huggingface-hub>=0.7.0\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 489 kB 50.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.70.12.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.3.4)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 491 kB 74.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.21.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from evaluate) (4.62.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.3.3)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 193 kB 74.2 MB/s            \n",
      "\u001b[?25hCollecting requests>=2.19.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64 kB 754 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-20.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.3 MB 44.1 MB/s            \n",
      "\u001b[?25hCollecting tqdm>=4.62.1\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 7.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->evaluate) (3.0.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: tqdm, requests, fsspec, pyarrow, huggingface-hub, datasets, evaluate\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.11.1\n",
      "    Uninstalling fsspec-2021.11.1:\n",
      "      Successfully uninstalled fsspec-2021.11.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 6.0.1\n",
      "    Uninstalling pyarrow-6.0.1:\n",
      "      Successfully uninstalled pyarrow-6.0.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.0.19\n",
      "    Uninstalling huggingface-hub-0.0.19:\n",
      "      Successfully uninstalled huggingface-hub-0.0.19\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.14.0\n",
      "    Uninstalling datasets-1.14.0:\n",
      "      Successfully uninstalled datasets-1.14.0\n",
      "Successfully installed datasets-3.6.0 evaluate-0.4.3 fsspec-2025.3.0 huggingface-hub-0.31.4 pyarrow-20.0.0 requests-2.32.3 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5aa71d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 20.0.0\n",
      "Uninstalling pyarrow-20.0.0:\n",
      "  Successfully uninstalled pyarrow-20.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-20.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Found existing installation: datasets 3.6.0\n",
      "Uninstalling datasets-3.6.0:\n",
      "  Successfully uninstalled datasets-3.6.0\n",
      "Found existing installation: evaluate 0.4.3\n",
      "Uninstalling evaluate-0.4.3:\n",
      "  Successfully uninstalled evaluate-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.31.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets) (1.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.9/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.9/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: datasets, evaluate\n",
      "Successfully installed datasets-3.6.0 evaluate-0.4.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pyarrow -y\n",
    "!pip install pyarrow --upgrade\n",
    "!pip uninstall datasets evaluate -y\n",
    "!pip install datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5da00f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Perplexity (PPL): 1.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9602383136784436"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_perplexity(model, val_dataset, loss_function):\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for enc_batch, dec_in_batch, dec_out_batch in val_dataset:\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(enc_batch, dec_in_batch)\n",
    "        predictions, _, _, _ = model(enc_batch, dec_in_batch, enc_mask, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        loss = loss_function(dec_out_batch, predictions)\n",
    "        token_count = tf.reduce_sum(tf.cast(dec_out_batch != 0, tf.float32)).numpy()\n",
    "        \n",
    "        total_loss += loss.numpy() * token_count\n",
    "        total_tokens += token_count\n",
    "\n",
    "    perplexity = np.exp(total_loss / total_tokens)\n",
    "    print(f\"ğŸ§  Perplexity (PPL): {perplexity:.4f}\")\n",
    "    return perplexity\n",
    "compute_perplexity(transformer, val_dataset, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a9fa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y):\n",
    "    m, n = len(X), len(Y)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if X[i] == Y[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    return dp[m][n]\n",
    "\n",
    "def rouge_l_score(reference, hypothesis):\n",
    "    ref_tokens = reference.split()\n",
    "    hyp_tokens = hypothesis.split()\n",
    "    \n",
    "    lcs_len = lcs(ref_tokens, hyp_tokens)\n",
    "\n",
    "    prec = lcs_len / len(hyp_tokens) if hyp_tokens else 0.0\n",
    "    rec = lcs_len / len(ref_tokens) if ref_tokens else 0.0\n",
    "    if prec + rec == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * prec * rec / (prec + rec)\n",
    "    \n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ef76b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# âœ… ROUGE-L ê³„ì‚° í•¨ìˆ˜ (ì„¤ì¹˜ í•„ìš” ì—†ìŒ)\n",
    "def rouge_l_score(reference, hypothesis):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    ref_len = len(ref_words)\n",
    "    hyp_len = len(hyp_words)\n",
    "\n",
    "    # LCS (ìµœì¥ ê³µí†µ ë¶€ë¶„ ìˆ˜ì—´)\n",
    "    lcs_matrix = [[0] * (hyp_len + 1) for _ in range(ref_len + 1)]\n",
    "\n",
    "    for i in range(ref_len):\n",
    "        for j in range(hyp_len):\n",
    "            if ref_words[i] == hyp_words[j]:\n",
    "                lcs_matrix[i+1][j+1] = lcs_matrix[i][j] + 1\n",
    "            else:\n",
    "                lcs_matrix[i+1][j+1] = max(lcs_matrix[i][j+1], lcs_matrix[i+1][j])\n",
    "\n",
    "    lcs_len = lcs_matrix[-1][-1]\n",
    "\n",
    "    recall = lcs_len / ref_len if ref_len > 0 else 0.0\n",
    "    precision = lcs_len / hyp_len if hyp_len > 0 else 0.0\n",
    "    f1 = 2 * recall * precision / (recall + precision + 1e-8)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2b8d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, val_dataset, loss_function):\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for enc_batch, dec_in_batch, dec_out_batch in val_dataset:\n",
    "        enc_mask, dec_enc_mask, dec_mask = generate_masks(enc_batch, dec_in_batch)\n",
    "        predictions, _, _, _ = model(enc_batch, dec_in_batch, enc_mask, dec_enc_mask, dec_mask)\n",
    "        mask = tf.cast(dec_out_batch != 0, tf.float32)\n",
    "        loss = loss_function(dec_out_batch, predictions)\n",
    "        total_loss += loss.numpy() * tf.reduce_sum(mask).numpy()\n",
    "        total_tokens += tf.reduce_sum(mask).numpy()\n",
    "\n",
    "    perplexity = np.exp(total_loss / total_tokens)\n",
    "    print(f\"\\nğŸ§  Perplexity (PPL): {perplexity:.4f}\")\n",
    "    return perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3092f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_rouge(model, src_sentences, tgt_sentences, tokenizer, num_examples=5):\n",
    "    total_rouge = 0.0\n",
    "    count = 0\n",
    "\n",
    "    print(\"ğŸ§ª ROUGE-L í‰ê°€ ì‹œì‘...\\n\")\n",
    "\n",
    "    for idx in tqdm(range(len(src_sentences))):\n",
    "        src = src_sentences.iloc[idx] if isinstance(src_sentences, pd.Series) else src_sentences[idx]\n",
    "        ref = tgt_sentences.iloc[idx] if isinstance(tgt_sentences, pd.Series) else tgt_sentences[idx]\n",
    "\n",
    "\n",
    "        try:\n",
    "            hyp = evaluate(src)  # ğŸ”§ ì‚¬ìš©ì ì •ì˜ ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "            rouge = rouge_l_score(ref, hyp)\n",
    "            total_rouge += rouge\n",
    "            count += 1\n",
    "\n",
    "            if idx < num_examples:\n",
    "                print(f\"\\nğŸ“Œ ì˜ˆì‹œ {idx + 1}\")\n",
    "                print(f\"ğŸ‘‰ ì…ë ¥:  {src}\")\n",
    "                print(f\"âœ… ì •ë‹µ:  {ref}\")\n",
    "                print(f\"ğŸ§  ì˜ˆì¸¡:  {hyp}\")\n",
    "                print(f\"ğŸ“ ROUGE-L F1: {rouge:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜ at {idx}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\nğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
    "    print(f\"âœ… í‰ê·  ROUGE-L F1: {total_rouge / count:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83afd752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª ROUGE-L í‰ê°€ ì‹œì‘...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3265 [00:00<51:41,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 1\n",
      "ğŸ‘‰ ì…ë ¥:  ì´ ë³„í›„ ëŠë¼ ëŠ” ê°ì • ë“¤ ì´ ë‹¨ê³„ ë³„ ë¡œ ìˆ ëŠ” ê±° ê°™ ë„¤\n",
      "âœ… ì •ë‹µ:  ê·¸ê²Œ ì¶”ì–µ ì˜ ìœ ì  ì¸ê°€ ë´ìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:  ê·¸ê²Œ ì¶”ì–µ ì˜ ëª¨ìŠµ ê³¼ í•¨ê»˜ ì— ëŒ€í•œ ì‹œê°„ ì´ ì—ˆ ë‹¤ë©´ ë³€í™” ê°€ ëª… ìœ¼ë‹ˆê¹Œìš” .\n",
      "ğŸ“ ROUGE-L F1: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/3265 [00:01<49:46,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 2\n",
      "ğŸ‘‰ ì…ë ¥:  ê°„ì‹ í´ë” ë½‘ ëŠ” ê±° í˜ë“œ ë„¤\n",
      "âœ… ì •ë‹µ:  ëˆ„êµ¬ ë‘ ë¨¹ ëŠ” ëƒ ì— ë”°ë¼ ë‹¤ë¥´ ê²  ì£  .\n",
      "ğŸ§  ì˜ˆì¸¡:  ìŠ¬í”” í•˜ ê¸° ë„ ì‹œí‚¤ ì§€ ì•Š ëŠ” ì•½ê°„ ì˜ ë°©ì‹ ì´ ì—ìš” .\n",
      "ğŸ“ ROUGE-L F1: 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/3265 [00:02<40:23,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 3\n",
      "ğŸ‘‰ ì…ë ¥:  ì—°ì•  ì¤‘ ì¸ë° ì™¸ë¡œìš´ ëŠë‚Œ ì´ ë“¤ ë©´ ë¬¸ì œ ì¼ê¹Œ ?\n",
      "âœ… ì •ë‹µ:  ì‚¬ëŒ ì€ ë‹¤ ì™¸ë¡œìš´ ì¡´ì¬ ì˜ˆìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:  ì Šì€ì´ ì€ ë‹¤ ì™¸ë¡œìš´ í˜„ì¡´ ì˜ˆìš” .\n",
      "ğŸ“ ROUGE-L F1: 0.7143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/3265 [00:02<34:52,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 4\n",
      "ğŸ‘‰ ì…ë ¥:  ì´ëŸ° í—¤ì–´ì§€\n",
      "âœ… ì •ë‹µ:  í”í•˜ ì§€ ì•Š ì£  .\n",
      "ğŸ§  ì˜ˆì¸¡:  ëª¨ë¥´ ë‹¤ê°€ ë„ ì•ˆ ë¼ìš” .\n",
      "ğŸ“ ROUGE-L F1: 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/3265 [00:03<35:47,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì˜ˆì‹œ 5\n",
      "ğŸ‘‰ ì…ë ¥:  ê°•ì•„ì§€ í‚¤ìš° ê³  ì‹¶ ì–´\n",
      "âœ… ì •ë‹µ:  ì£„ì±… ì§ˆ ìˆ˜ ì—† ì„ ê²½ìš° í‚¤ì›Œ ë³´ ì„¸ìš” .\n",
      "ğŸ§  ì˜ˆì¸¡:  ê³¼ì‹¤ ì§ˆ ìˆ˜ ì—†ì—ˆ ì„ ë•Œì¯¤ í‚¤ì›Œ ë³´ ì„¸ìš” .\n",
      "ğŸ“ ROUGE-L F1: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3265/3265 [33:05<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š ìµœì¢… ê²°ê³¼\n",
      "âœ… í‰ê·  ROUGE-L F1: 0.6708\n",
      "\n",
      "ğŸ§  Perplexity (PPL): 1.9602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.960238318502801"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ROUGE-L ê³„ì‚°\n",
    "evaluate_rouge(\n",
    "    model=transformer,\n",
    "    src_sentences=src_val_sentences,\n",
    "    tgt_sentences=tgt_val_sentences,\n",
    "    tokenizer=sp,  # SentencePiece tokenizer\n",
    "    num_examples=5\n",
    ")\n",
    "\n",
    "# Perplexity ê³„ì‚°\n",
    "compute_perplexity(\n",
    "    model=transformer,\n",
    "    val_dataset=val_dataset,\n",
    "    loss_function=loss_function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b5179",
   "metadata": {},
   "source": [
    "# ê²°ê³¼ ì •ë¦¬\n",
    "- dropoutì„ 0.3->0.5ë¡œ í•  ë•Œ ë³€í™”ê°€ ëˆˆì— ë„ëŠ”ë°,\n",
    "0.3ì¼ ë•ŒëŠ” ê¸¸ê³  ì•ˆì •ì ì¸ ë¬¸ì¥ì„ ë±‰ëŠ” ë°˜ë©´\n",
    "0.5ì¼ ë•ŒëŠ” ì§§ê³  ì˜ë¯¸ì—†ëŠ” ë¬¸ì¥ì„ ë±‰ëŠ” ê²½ìš°ê°€ ë§ì•˜ìŠµë‹ˆë‹¤.\n",
    "[SRC]  ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\n",
    "[GEN]:  ['<start>', 'ì„¸ìš”', '.<end>']\n",
    "[TGT]  ['ì¢‹', 'ì•„', 'í•˜', 'ë©´', 'ê·¸ëŸ´', 'ìˆ˜', 'ìˆ', 'ì–´ìš”', '.']\n",
    "[SRC]  ì§‘ì— ìˆëŠ”ë‹¤ëŠ” ì†Œë¦¬ì•¼.\n",
    "[GEN]:  ['<start>', 'ì§€ì¼œ', 'ì£¼', 'ì„¸ìš”', '.<end>']\n",
    "[TGT]  ['ì¢‹', 'ì•„', 'í•˜', 'ë©´', 'ê·¸ëŸ´', 'ìˆ˜', 'ìˆ', 'ì–´ìš”', '.']\n",
    "- augmentation í•  ë•Œ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ê²ƒìœ¼ë¡œ ë‹¨ì–´ë¥¼ ëŒ€ì²´í•˜ë‹¤ë³´ë‹ˆ ì˜ˆì¸¡í•œ ë‹µë³€ë„ ë‹¨ì–´ë¥¼ ëŒ€ì²´í•´ì„œ ë§Œë“¤ì–´ì§„ ë¬¸ì¥ì´ ë§ë‹¤. \n",
    "- ê·¸ë ‡ë‹¤ë³´ë‹ˆ ë¬¸ë²•ì ìœ¼ë¡œ ì–´ìƒ‰í•œ ë¬¸ì¥ì´ ë§ì€ ê²ƒ ê°™ë‹¤. \n",
    "- ë°ì´í„°ê°€ 3ë§Œê°œ ì •ë„ë¡œ ì ë‹¤ ë³´ë‹ˆ ì •ì„±ì ìœ¼ë¡œ ë³´ë‚˜ ì •ëŸ‰ì ìœ¼ë¡œ ë³´ë‚˜ ì•„ì‰¬ìš´ ê²°ê³¼ë¥¼ ì–»ì€ ê²ƒ ê°™ë‹¤. \n",
    "- augmentation í•˜ëŠ” ë°©ì‹ì„ ë‹¤ì–‘í•˜ê²Œ ì‹œë„í•´ë³´ë©´ ì¢€ë” í•™ìŠµì´ ì˜ ë˜ì§€ ì•Ÿì„ê¹Œ ìƒê°ì´ ëœë‹¤. \n",
    "- epochìˆ˜ëŠ” 10ì„ ë„˜ì§€ ì•ŠëŠ”ê²ƒì´ ê³¼ì í•©ë˜ì§€ ì•ŠëŠ”ê²ƒ ê°™ë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91434377",
   "metadata": {},
   "source": [
    "# íšŒê³ \n",
    "- ê³¼ëŒ€ì í•©ì„ ë§‰ê¸°ìœ„í•´ d_ff =[2048, 1024], dropout = [0.3, 0.5]ë¡œ ì‹¤í—˜ì„ í•˜ì˜€ìœ¼ë‚˜ ì²˜ìŒ ë§Œë“  baseline ëª¨ë¸ì´ ë” ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. (ì •ì„±ì  í‰ê°€ë¡œ ì˜ˆë¬¸ ì¶œë ¥ì„ í™•ì¸í–ˆì„ ë•Œ)\n",
    "- dropout 0.5ì¸ ê²½ìš° ì§§ê³  ì˜ë¯¸ ì—†ëŠ” ë¬¸ì¥ì„ ìƒì„±í•˜ì˜€ë‹¤.  \n",
    "\n",
    "    \" ì„¸ìš” . '\n",
    "    \" ì—ìš” . '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99cb080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
